{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import tqdm\n",
    "import glob\n",
    "import os\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import librosa\n",
    "import keras\n",
    "from keras.layers import Conv2D,MaxPool2D,BatchNormalization,Input,Activation,MaxPool1D,Conv1D\n",
    "from keras.layers import CuDNNGRU as GRU\n",
    "from keras.layers import CuDNNLSTM as LSTM\n",
    "from keras.layers import Reshape, Bidirectional,Flatten,Dense,InputLayer,Permute,Multiply"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_root = \"/home/philip/data/Keyword_spot/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_indices = {\n",
    "'bed': 0, 'bird': 1, 'cat': 2, 'dog': 3, 'down': 4, 'eight': 5, 'five': 6, 'four': 7, 'go': 8, 'happy': 9, 'house': 10, 'left': 11,\n",
    " 'marvin': 12, 'nine': 13, 'no': 14, 'off': 15, 'on': 16, 'one': 17, 'right': 18, 'seven': 19, 'sheila': 20, 'six': 21, 'stop': 22,\n",
    " 'three': 23, 'tree': 24, 'two': 25, 'up': 26, 'wow': 27, 'yes': 28, 'zero': 29}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_num=len(class_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from keras import backend as K\n",
    "\n",
    "K.set_learning_phase(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_class_file = glob.glob(data_root+\"train/audio/***/*.wav\")\n",
    "all_silence_file = glob.glob(data_root+\"train/silence/*.wav\")+glob.glob(data_root+\"train/silence_bg/*.wav\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_seq_from_filename(filename):\n",
    "    try:\n",
    "        y,sr = librosa.load(filename,sr=16000)\n",
    "    except:\n",
    "        print(filename)\n",
    "    if len(y)<16000:\n",
    "        pad_with = (16000-len(y))//2+1\n",
    "        y = np.pad(y,pad_with,'constant')[:16000]\n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_label_from_filename(full_filename):\n",
    "    dirname = os.path.dirname(full_filename)\n",
    "    label = dirname.split(\"/\")[-1]\n",
    "    label_indice = class_indices[label]\n",
    "    one_hot_encode = keras.utils.to_categorical(label_indice,len(class_indices))\n",
    "    return one_hot_encode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_label = np.squeeze(np.array([get_label_from_filename(_) for _ in all_class_file],np.float32))\n",
    "all_class_file = np.array(all_class_file)\n",
    "non_silence_label = np.ones_like(all_class_file,np.float32)\n",
    "non_silence_label = np.expand_dims(non_silence_label,1)\n",
    "silence_label_cls = np.zeros((len(all_silence_file),class_num),np.float32)\n",
    "all_silence_file = np.array(all_silence_file)\n",
    "silence_label_bin = np.zeros_like(all_silence_file,np.float32)\n",
    "silence_label_bin = np.expand_dims(silence_label_bin,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# all_class_file = np.array(list(map(get_seq_from_filename,all_class_file)),np.float32)\n",
    "# all_silence_file = np.array(list(map(get_seq_from_filename,all_silence_file)),np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# binary_class_dataset_audio = tf.data.Dataset.from_tensor_slices(all_training_file)\n",
    "# binary_class_dataset_silence = tf.data.Dataset.from_tensor_slices(all_silence_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "class_data_set = tf.data.Dataset.from_tensor_slices((all_class_file,class_label, non_silence_label))\n",
    "silence_data_set = tf.data.Dataset.from_tensor_slices((all_silence_file,silence_label_cls,silence_label_bin))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sequence_from_file(filename,class_label,binary_label):\n",
    "    data = tf.read_file(filename)\n",
    "    audio_seq = tf.contrib.ffmpeg.decode_audio(data,file_format='wav',samples_per_second=16000,channel_count=1)\n",
    "    pad = tf.concat([audio_seq, tf.zeros((16000,1))],0)[:16000] \n",
    "    return pad,class_label,binary_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "class_batch_size = int(batch_size*0.75)\n",
    "silence_batch_size = int(batch_size*0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_data_set = class_data_set.map(get_sequence_from_file,num_parallel_calls=6)\n",
    "silence_data_set = silence_data_set.map(get_sequence_from_file,num_parallel_calls=6)\n",
    "class_data_set = class_data_set.shuffle(buffer_size=6400).batch(class_batch_size).repeat()\n",
    "silence_data_set = silence_data_set.shuffle(buffer_size=1600).batch(silence_batch_size).repeat()\n",
    "next_batch_class = class_data_set.make_one_shot_iterator().get_next()\n",
    "next_batch_silence = silence_data_set.make_one_shot_iterator().get_next()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_data_set = class_data_set.batch(class_batch_size)\n",
    "silence_data_set = silence_data_set.batch(silence_batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "next_batch = [tf.concat((a,b),0) for a,b in zip(next_batch_class,next_batch_silence)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv_1d_model(inputs):\n",
    "    x = Conv1D(128,512,padding='same',activation='relu', dilation_rate=4)(inputs)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = MaxPool1D(pool_size=(20),strides=10)(x)\n",
    "    x = Conv1D(256,256,padding='same', activation='relu',dilation_rate=4)(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = MaxPool1D(pool_size=(20),strides=10)(x)\n",
    "    x = Bidirectional(LSTM(256,return_sequences=True),merge_mode='ave')(x)\n",
    "    x = Bidirectional(LSTM(256,return_sequences=True),merge_mode='ave')(x)    \n",
    "    a = Permute((2,1))(x)\n",
    "    a = Dense(158, activation='softmax',input_dim=(158))(a)\n",
    "    a = Permute((2,1))(a)\n",
    "    x = Multiply()([x,a])\n",
    "    o = MaxPool1D(158)(x)\n",
    "    o = Flatten()(o)\n",
    "    return o\n",
    "\n",
    "def build_multi_task(input_sequence,class_label,binary_label):\n",
    "    flatten_last = conv_1d_model(input_sequence)\n",
    "    binary_head = Dense(1,activation='sigmoid')(flatten_last)\n",
    "    class_head = Dense(30,activation='softmax')(flatten_last)\n",
    "    class_loss = keras.losses.categorical_crossentropy(class_label,class_head)\n",
    "    binary_loss = keras.losses.binary_crossentropy(binary_label,binary_head)\n",
    "    total_loss = tf.reduce_mean(binary_label*class_loss+binary_loss)\n",
    "    return total_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_sequence = tf.placeholder(tf.float32,[None,16000,1])\n",
    "class_label = tf.placeholder(tf.float32,[None,30])\n",
    "binary_label = tf.placeholder(tf.float32,[None,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "total_loss = build_multi_task(input_sequence,class_label,binary_label)\n",
    "# total_loss = build_multi_task(*next_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_op = tf.train.AdamOptimizer().minimize(total_loss)\n",
    "train_op = tf.train.GradientDescentOptimizer(1e-3).minimize(total_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess = tf.InteractiveSession()\n",
    "init_op = tf.global_variables_initializer()\n",
    "sess.run(init_op)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "losses = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9935beaaa8674443a7a00b2ef9684ebe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "<p>Failed to display Jupyter Widget of type <code>HBox</code>.</p>\n",
       "<p>\n",
       "  If you're reading this message in the Jupyter Notebook or JupyterLab Notebook, it may mean\n",
       "  that the widgets JavaScript is still loading. If this message persists, it\n",
       "  likely means that the widgets JavaScript library is either not installed or\n",
       "  not enabled. See the <a href=\"https://ipywidgets.readthedocs.io/en/stable/user_install.html\">Jupyter\n",
       "  Widgets Documentation</a> for setup instructions.\n",
       "</p>\n",
       "<p>\n",
       "  If you're reading this message in another frontend (for example, a static\n",
       "  rendering on GitHub or <a href=\"https://nbviewer.jupyter.org/\">NBViewer</a>),\n",
       "  it may mean that your frontend doesn't currently support widgets.\n",
       "</p>\n"
      ],
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=600), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "InvalidArgumentError",
     "evalue": "ConcatOp : Dimensions of inputs should match: shape[0] = [0,0] vs. shape[1] = [16000,1]\n\t [[Node: concat = ConcatV2[N=2, T=DT_FLOAT, Tidx=DT_INT32](DecodeAudioV2, zeros, concat/axis)]]\n\t [[Node: IteratorGetNext_1 = IteratorGetNext[output_shapes=[[?,?,1], [?,30], [?,1]], output_types=[DT_FLOAT, DT_FLOAT, DT_FLOAT], _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](OneShotIterator_1)]]\n\t [[Node: IteratorGetNext_1/_11 = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/device:GPU:0\", send_device=\"/job:localhost/replica:0/task:0/device:CPU:0\", send_device_incarnation=1, tensor_name=\"edge_12_IteratorGetNext_1\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"]()]]\n\nCaused by op 'concat', defined at:\n  File \"/home/philip/.conda/envs/py3/lib/python3.6/runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"/home/philip/.conda/envs/py3/lib/python3.6/runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"/home/philip/.conda/envs/py3/lib/python3.6/site-packages/ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"/home/philip/.conda/envs/py3/lib/python3.6/site-packages/traitlets/config/application.py\", line 658, in launch_instance\n    app.start()\n  File \"/home/philip/.conda/envs/py3/lib/python3.6/site-packages/ipykernel/kernelapp.py\", line 478, in start\n    self.io_loop.start()\n  File \"/home/philip/.conda/envs/py3/lib/python3.6/site-packages/zmq/eventloop/ioloop.py\", line 177, in start\n    super(ZMQIOLoop, self).start()\n  File \"/home/philip/.conda/envs/py3/lib/python3.6/site-packages/tornado/ioloop.py\", line 888, in start\n    handler_func(fd_obj, events)\n  File \"/home/philip/.conda/envs/py3/lib/python3.6/site-packages/tornado/stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/home/philip/.conda/envs/py3/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 440, in _handle_events\n    self._handle_recv()\n  File \"/home/philip/.conda/envs/py3/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 472, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"/home/philip/.conda/envs/py3/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 414, in _run_callback\n    callback(*args, **kwargs)\n  File \"/home/philip/.conda/envs/py3/lib/python3.6/site-packages/tornado/stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/home/philip/.conda/envs/py3/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 281, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"/home/philip/.conda/envs/py3/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 232, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"/home/philip/.conda/envs/py3/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 397, in execute_request\n    user_expressions, allow_stdin)\n  File \"/home/philip/.conda/envs/py3/lib/python3.6/site-packages/ipykernel/ipkernel.py\", line 208, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/home/philip/.conda/envs/py3/lib/python3.6/site-packages/ipykernel/zmqshell.py\", line 533, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/home/philip/.conda/envs/py3/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2728, in run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/home/philip/.conda/envs/py3/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2850, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"/home/philip/.conda/envs/py3/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2910, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-18-ae6497d9c5dd>\", line 1, in <module>\n    next_batch = [tf.concat((a,b),0) for a,b in zip(next_batch_class,next_batch_silence)]\n  File \"<ipython-input-18-ae6497d9c5dd>\", line 1, in <listcomp>\n    next_batch = [tf.concat((a,b),0) for a,b in zip(next_batch_class,next_batch_silence)]\n  File \"/home/philip/.conda/envs/py3/lib/python3.6/site-packages/tensorflow/python/ops/array_ops.py\", line 1099, in concat\n    return gen_array_ops._concat_v2(values=values, axis=axis, name=name)\n  File \"/home/philip/.conda/envs/py3/lib/python3.6/site-packages/tensorflow/python/ops/gen_array_ops.py\", line 706, in _concat_v2\n    \"ConcatV2\", values=values, axis=axis, name=name)\n  File \"/home/philip/.conda/envs/py3/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py\", line 787, in _apply_op_helper\n    op_def=op_def)\n  File \"/home/philip/.conda/envs/py3/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 2956, in create_op\n    op_def=op_def)\n  File \"/home/philip/.conda/envs/py3/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 1470, in __init__\n    self._traceback = self._graph._extract_stack()  # pylint: disable=protected-access\n\nInvalidArgumentError (see above for traceback): ConcatOp : Dimensions of inputs should match: shape[0] = [0,0] vs. shape[1] = [16000,1]\n\t [[Node: concat = ConcatV2[N=2, T=DT_FLOAT, Tidx=DT_INT32](DecodeAudioV2, zeros, concat/axis)]]\n\t [[Node: IteratorGetNext_1 = IteratorGetNext[output_shapes=[[?,?,1], [?,30], [?,1]], output_types=[DT_FLOAT, DT_FLOAT, DT_FLOAT], _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](OneShotIterator_1)]]\n\t [[Node: IteratorGetNext_1/_11 = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/device:GPU:0\", send_device=\"/job:localhost/replica:0/task:0/device:CPU:0\", send_device_incarnation=1, tensor_name=\"edge_12_IteratorGetNext_1\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"]()]]\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m~/.conda/envs/py3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1301\u001b[0m                                    \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1302\u001b[0;31m                                    status, run_metadata)\n\u001b[0m\u001b[1;32m   1303\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: ",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[0;32m~/.conda/envs/py3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1322\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1323\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1324\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/py3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1301\u001b[0m                                    \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1302\u001b[0;31m                                    status, run_metadata)\n\u001b[0m\u001b[1;32m   1303\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/py3/lib/python3.6/site-packages/tensorflow/python/framework/errors_impl.py\u001b[0m in \u001b[0;36m__exit__\u001b[0;34m(self, type_arg, value_arg, traceback_arg)\u001b[0m\n\u001b[1;32m    472\u001b[0m             \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mc_api\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_Message\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 473\u001b[0;31m             c_api.TF_GetCode(self.status.status))\n\u001b[0m\u001b[1;32m    474\u001b[0m     \u001b[0;31m# Delete the underlying status object from memory otherwise it stays alive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: ConcatOp : Dimensions of inputs should match: shape[0] = [0,0] vs. shape[1] = [16000,1]\n\t [[Node: concat = ConcatV2[N=2, T=DT_FLOAT, Tidx=DT_INT32](DecodeAudioV2, zeros, concat/axis)]]\n\t [[Node: IteratorGetNext_1 = IteratorGetNext[output_shapes=[[?,?,1], [?,30], [?,1]], output_types=[DT_FLOAT, DT_FLOAT, DT_FLOAT], _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](OneShotIterator_1)]]\n\t [[Node: IteratorGetNext_1/_11 = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/device:GPU:0\", send_device=\"/job:localhost/replica:0/task:0/device:CPU:0\", send_device_incarnation=1, tensor_name=\"edge_12_IteratorGetNext_1\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"]()]]",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-54-527707239850>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtqdm_notebook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m600\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mbatch_sequence\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_class_label\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbatch_binary\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnext_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     loss,_ = sess.run([total_loss,train_op],feed_dict={input_sequence:batch_sequence,\n\u001b[1;32m      4\u001b[0m                                                       \u001b[0mclass_label\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mbatch_class_label\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m                                                       binary_label:batch_binary})\n",
      "\u001b[0;32m~/.conda/envs/py3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    887\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 889\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    890\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    891\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/py3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1118\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1119\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1120\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1121\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1122\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/py3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1315\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1316\u001b[0m       return self._do_call(_run_fn, self._session, feeds, fetches, targets,\n\u001b[0;32m-> 1317\u001b[0;31m                            options, run_metadata)\n\u001b[0m\u001b[1;32m   1318\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1319\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/py3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1334\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1335\u001b[0m           \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1336\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1337\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1338\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: ConcatOp : Dimensions of inputs should match: shape[0] = [0,0] vs. shape[1] = [16000,1]\n\t [[Node: concat = ConcatV2[N=2, T=DT_FLOAT, Tidx=DT_INT32](DecodeAudioV2, zeros, concat/axis)]]\n\t [[Node: IteratorGetNext_1 = IteratorGetNext[output_shapes=[[?,?,1], [?,30], [?,1]], output_types=[DT_FLOAT, DT_FLOAT, DT_FLOAT], _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](OneShotIterator_1)]]\n\t [[Node: IteratorGetNext_1/_11 = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/device:GPU:0\", send_device=\"/job:localhost/replica:0/task:0/device:CPU:0\", send_device_incarnation=1, tensor_name=\"edge_12_IteratorGetNext_1\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"]()]]\n\nCaused by op 'concat', defined at:\n  File \"/home/philip/.conda/envs/py3/lib/python3.6/runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"/home/philip/.conda/envs/py3/lib/python3.6/runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"/home/philip/.conda/envs/py3/lib/python3.6/site-packages/ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"/home/philip/.conda/envs/py3/lib/python3.6/site-packages/traitlets/config/application.py\", line 658, in launch_instance\n    app.start()\n  File \"/home/philip/.conda/envs/py3/lib/python3.6/site-packages/ipykernel/kernelapp.py\", line 478, in start\n    self.io_loop.start()\n  File \"/home/philip/.conda/envs/py3/lib/python3.6/site-packages/zmq/eventloop/ioloop.py\", line 177, in start\n    super(ZMQIOLoop, self).start()\n  File \"/home/philip/.conda/envs/py3/lib/python3.6/site-packages/tornado/ioloop.py\", line 888, in start\n    handler_func(fd_obj, events)\n  File \"/home/philip/.conda/envs/py3/lib/python3.6/site-packages/tornado/stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/home/philip/.conda/envs/py3/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 440, in _handle_events\n    self._handle_recv()\n  File \"/home/philip/.conda/envs/py3/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 472, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"/home/philip/.conda/envs/py3/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 414, in _run_callback\n    callback(*args, **kwargs)\n  File \"/home/philip/.conda/envs/py3/lib/python3.6/site-packages/tornado/stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/home/philip/.conda/envs/py3/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 281, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"/home/philip/.conda/envs/py3/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 232, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"/home/philip/.conda/envs/py3/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 397, in execute_request\n    user_expressions, allow_stdin)\n  File \"/home/philip/.conda/envs/py3/lib/python3.6/site-packages/ipykernel/ipkernel.py\", line 208, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/home/philip/.conda/envs/py3/lib/python3.6/site-packages/ipykernel/zmqshell.py\", line 533, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/home/philip/.conda/envs/py3/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2728, in run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/home/philip/.conda/envs/py3/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2850, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"/home/philip/.conda/envs/py3/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2910, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-18-ae6497d9c5dd>\", line 1, in <module>\n    next_batch = [tf.concat((a,b),0) for a,b in zip(next_batch_class,next_batch_silence)]\n  File \"<ipython-input-18-ae6497d9c5dd>\", line 1, in <listcomp>\n    next_batch = [tf.concat((a,b),0) for a,b in zip(next_batch_class,next_batch_silence)]\n  File \"/home/philip/.conda/envs/py3/lib/python3.6/site-packages/tensorflow/python/ops/array_ops.py\", line 1099, in concat\n    return gen_array_ops._concat_v2(values=values, axis=axis, name=name)\n  File \"/home/philip/.conda/envs/py3/lib/python3.6/site-packages/tensorflow/python/ops/gen_array_ops.py\", line 706, in _concat_v2\n    \"ConcatV2\", values=values, axis=axis, name=name)\n  File \"/home/philip/.conda/envs/py3/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py\", line 787, in _apply_op_helper\n    op_def=op_def)\n  File \"/home/philip/.conda/envs/py3/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 2956, in create_op\n    op_def=op_def)\n  File \"/home/philip/.conda/envs/py3/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 1470, in __init__\n    self._traceback = self._graph._extract_stack()  # pylint: disable=protected-access\n\nInvalidArgumentError (see above for traceback): ConcatOp : Dimensions of inputs should match: shape[0] = [0,0] vs. shape[1] = [16000,1]\n\t [[Node: concat = ConcatV2[N=2, T=DT_FLOAT, Tidx=DT_INT32](DecodeAudioV2, zeros, concat/axis)]]\n\t [[Node: IteratorGetNext_1 = IteratorGetNext[output_shapes=[[?,?,1], [?,30], [?,1]], output_types=[DT_FLOAT, DT_FLOAT, DT_FLOAT], _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](OneShotIterator_1)]]\n\t [[Node: IteratorGetNext_1/_11 = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/device:GPU:0\", send_device=\"/job:localhost/replica:0/task:0/device:CPU:0\", send_device_incarnation=1, tensor_name=\"edge_12_IteratorGetNext_1\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"]()]]\n"
     ]
    }
   ],
   "source": [
    "for i in tqdm.tqdm_notebook(range(600)):\n",
    "    batch_sequence, batch_class_label,batch_binary = sess.run(next_batch)\n",
    "    loss,_ = sess.run([total_loss,train_op],feed_dict={input_sequence:batch_sequence,\n",
    "                                                      class_label:batch_class_label,\n",
    "                                                      binary_label:batch_binary})\n",
    "#     print(i,loss)\n",
    "    losses.append(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f2338ff7400>]"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f23ac6cbc18>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "plt.plot(losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.plot(losses[:200])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## the plan is to:\n",
    "1. trian a binary classifier to judge if it is a silence audio or not\n",
    "2. train a multi class classifier to predict the exact class if it is not silent\n",
    "3. trian a multi-task classifier to do both thing metioned above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get data from generator and pad within it\n",
    "def audio_gen():\n",
    "    for filename in all_training_file:\n",
    "        y,sr = librosa.load(filename,sr=16000)\n",
    "        if len(y)<16000:\n",
    "            pad_with = (16000-len(y))//2+1\n",
    "            y = np.pad(y,pad_with,'constant')[:16000]\n",
    "        yield y\n",
    "        \n",
    "def silence_gen():\n",
    "    for filename in all_silence_file:\n",
    "        y,sr = librosa.load(filename,sr=16000)\n",
    "        if len(y)<16000:\n",
    "            pad_with = (16000-len(y))//2+1\n",
    "            y = np.pad(y,pad_with,'constant')[:16000]\n",
    "        yield y\n",
    "\n",
    "data_a = tf.data.Dataset.from_generator(audio_gen,tf.float32)\n",
    "data_s = tf.data.Dataset.from_generator(silence_gen,tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_bin_0 = tf.data.Dataset.from_tensor_slices([0]).repeat(len(all_training_file))\n",
    "label_bin_1 = tf.data.Dataset.from_tensor_slices([1]).repeat(len(all_silence_file))\n",
    "data_a = data_a.zip((data_a,label_bin_0)).shuffle(buffer_size=320).batch(32).repeat()\n",
    "data_s = data_s.zip((data_s,label_bin_1)).shuffle(buffer_size=320).batch(32).repeat()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_sequence_from_file(filename):\n",
    "    y,sr = librosa.load(filename,sr=16000)\n",
    "    if load_audio:\n",
    "        return y\n",
    "    else:\n",
    "        mel = librosa.feature.melspectrogram(y,sr,hop_length=256)\n",
    "        db = librosa.power_to_db(mel, ref=np.min)\n",
    "        return db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "mapping_strings = tf.constant(list(class_indices.keys()))\n",
    "table = tf.contrib.lookup.index_table_from_tensor(mapping=mapping_strings, num_oov_buckets=1, default_value=-1)\n",
    "tf.tables_initializer().run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "# get data from tensorslice and pad with tensorflow method\n",
    "# Tensorflow Sucks! \n",
    "def get_silent_data(filename):\n",
    "    binary_label = tf.constant(0)\n",
    "    data = tf.read_file(filename)\n",
    "    audio_seq = tf.contrib.ffmpeg.decode_audio(data,file_format='wav',samples_per_second=16000,channel_count=1)\n",
    "    # tensorflow does not support 1-d data padding mothod, make sure everything is 16000\n",
    "    pad = tf.concat([audio_seq, tf.zeros((16000,1))],0)[:16000] \n",
    "    class_label=tf.constant(np.zeros(class_num,dtype=np.float32))\n",
    "    return pad,binary_label,class_label\n",
    "\n",
    "def get_label_from_filename(full_filename):\n",
    "    label = (tf.string_split(full_filename,'/').values)[-1]\n",
    "    label_indice = table.lookup(label)\n",
    "    one_hot_encode = tf.one_hot(label_indice,len(class_indices))\n",
    "    return one_hot_encode\n",
    "\n",
    "def get_class_data(filename):\n",
    "    binary_label = tf.constant(1)\n",
    "    class_label=tf.constant(get_label_from_filename(filename))\n",
    "    data = tf.read_file(filename)\n",
    "    audio_seq = tf.contrib.ffmpeg.decode_audio(data,file_format='wav',samples_per_second=16000,channel_count=1)\n",
    "    # tensorflow does not support 1-d data padding mothod, make sure everything is 16000\n",
    "    pad = tf.concat([audio_seq, tf.zeros((16000,1))],0)[:16000] \n",
    "    class_label=tf.constant(get_label_from_filename(filename))\n",
    "    return pad,binary_label,class_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Shape must be rank 1 but is rank 0 for 'StringSplit' (op: 'StringSplit') with input shapes: [], [].",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[0;32m/home/philip/anaconda2/envs/py3/lib/python3.6/site-packages/tensorflow/python/framework/common_shapes.py\u001b[0m in \u001b[0;36m_call_cpp_shape_fn_impl\u001b[0;34m(op, input_tensors_needed, input_tensors_as_shapes_needed, require_shape_fn)\u001b[0m\n\u001b[1;32m    685\u001b[0m           \u001b[0mgraph_def_version\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnode_def_str\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_shapes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_tensors\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 686\u001b[0;31m           input_tensors_as_shapes, status)\n\u001b[0m\u001b[1;32m    687\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mInvalidArgumentError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/philip/anaconda2/envs/py3/lib/python3.6/site-packages/tensorflow/python/framework/errors_impl.py\u001b[0m in \u001b[0;36m__exit__\u001b[0;34m(self, type_arg, value_arg, traceback_arg)\u001b[0m\n\u001b[1;32m    472\u001b[0m             \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mc_api\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_Message\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 473\u001b[0;31m             c_api.TF_GetCode(self.status.status))\n\u001b[0m\u001b[1;32m    474\u001b[0m     \u001b[0;31m# Delete the underlying status object from memory otherwise it stays alive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: Shape must be rank 1 but is rank 0 for 'StringSplit' (op: 'StringSplit') with input shapes: [], [].",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-63-24fd64a30554>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# data_s = binary_class_dataset_audio.map(get_silent_data).shuffle(buffer_size=320).batch(32)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdata_a\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbinary_class_dataset_silence\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mget_class_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbuffer_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m320\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/home/philip/anaconda2/envs/py3/lib/python3.6/site-packages/tensorflow/python/data/ops/dataset_ops.py\u001b[0m in \u001b[0;36mmap\u001b[0;34m(self, map_func, num_parallel_calls)\u001b[0m\n\u001b[1;32m    710\u001b[0m     \"\"\"\n\u001b[1;32m    711\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mnum_parallel_calls\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 712\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mMapDataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmap_func\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    713\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    714\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mParallelMapDataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmap_func\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_parallel_calls\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/philip/anaconda2/envs/py3/lib/python3.6/site-packages/tensorflow/python/data/ops/dataset_ops.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, input_dataset, map_func)\u001b[0m\n\u001b[1;32m   1383\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1384\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_map_func\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_map_func\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1385\u001b[0;31m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_map_func\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_to_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_default_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1386\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1387\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_as_variant_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/philip/anaconda2/envs/py3/lib/python3.6/site-packages/tensorflow/python/framework/function.py\u001b[0m in \u001b[0;36madd_to_graph\u001b[0;34m(self, g)\u001b[0m\n\u001b[1;32m    484\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0madd_to_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    485\u001b[0m     \u001b[0;34m\"\"\"Adds this function into the graph g.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 486\u001b[0;31m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_definition_if_needed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    487\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    488\u001b[0m     \u001b[0;31m# Adds this function into 'g'.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/philip/anaconda2/envs/py3/lib/python3.6/site-packages/tensorflow/python/framework/function.py\u001b[0m in \u001b[0;36m_create_definition_if_needed\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    319\u001b[0m     \u001b[0;34m\"\"\"Creates the function definition if it's not created yet.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    320\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgraph_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 321\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_definition_if_needed_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    322\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    323\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_create_definition_if_needed_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/philip/anaconda2/envs/py3/lib/python3.6/site-packages/tensorflow/python/framework/function.py\u001b[0m in \u001b[0;36m_create_definition_if_needed_impl\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    336\u001b[0m       \u001b[0;31m# Call func and gather the output tensors.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    337\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mvs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvariable_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcustom_getter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtemp_graph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetvar\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 338\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    339\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    340\u001b[0m       \u001b[0;31m# There is no way of distinguishing between a function not returning\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/philip/anaconda2/envs/py3/lib/python3.6/site-packages/tensorflow/python/data/ops/dataset_ops.py\u001b[0m in \u001b[0;36mtf_map_func\u001b[0;34m(*args)\u001b[0m\n\u001b[1;32m   1358\u001b[0m         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmap_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mnested_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1359\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1360\u001b[0;31m         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmap_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnested_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1361\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1362\u001b[0m       \u001b[0;31m# If `map_func` returns a list of tensors, `nest.flatten()` and\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-62-3c7ef187b450>\u001b[0m in \u001b[0;36mget_class_data\u001b[0;34m(filename)\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mget_class_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m     \u001b[0mbinary_label\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconstant\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m     \u001b[0mclass_label\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconstant\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mget_label_from_filename\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m     \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m     \u001b[0maudio_seq\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mffmpeg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode_audio\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mfile_format\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'wav'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msamples_per_second\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m16000\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mchannel_count\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-62-3c7ef187b450>\u001b[0m in \u001b[0;36mget_label_from_filename\u001b[0;34m(full_filename)\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mget_label_from_filename\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfull_filename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m     \u001b[0mlabel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstring_split\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfull_filename\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'/'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m     \u001b[0mlabel_indice\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtable\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlookup\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0mone_hot_encode\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mone_hot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabel_indice\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclass_indices\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/philip/anaconda2/envs/py3/lib/python3.6/site-packages/tensorflow/python/ops/string_ops.py\u001b[0m in \u001b[0;36mstring_split\u001b[0;34m(source, delimiter, skip_empty)\u001b[0m\n\u001b[1;32m     94\u001b[0m   \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m   indices, values, shape = gen_string_ops._string_split(\n\u001b[0;32m---> 96\u001b[0;31m       source, delimiter=delimiter, skip_empty=skip_empty)\n\u001b[0m\u001b[1;32m     97\u001b[0m   \u001b[0;31m# pylint: enable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m   \u001b[0mindices\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_shape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/philip/anaconda2/envs/py3/lib/python3.6/site-packages/tensorflow/python/ops/gen_string_ops.py\u001b[0m in \u001b[0;36m_string_split\u001b[0;34m(input, delimiter, skip_empty, name)\u001b[0m\n\u001b[1;32m    328\u001b[0m     _, _, _op = _op_def_lib._apply_op_helper(\n\u001b[1;32m    329\u001b[0m         \u001b[0;34m\"StringSplit\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdelimiter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdelimiter\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 330\u001b[0;31m         skip_empty=skip_empty, name=name)\n\u001b[0m\u001b[1;32m    331\u001b[0m     \u001b[0m_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_op\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    332\u001b[0m     \u001b[0m_inputs_flat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_op\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/philip/anaconda2/envs/py3/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py\u001b[0m in \u001b[0;36m_apply_op_helper\u001b[0;34m(self, op_type_name, name, **keywords)\u001b[0m\n\u001b[1;32m    785\u001b[0m         op = g.create_op(op_type_name, inputs, output_types, name=scope,\n\u001b[1;32m    786\u001b[0m                          \u001b[0minput_types\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_types\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattr_protos\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 787\u001b[0;31m                          op_def=op_def)\n\u001b[0m\u001b[1;32m    788\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0moutput_structure\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop_def\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_stateful\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    789\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/philip/anaconda2/envs/py3/lib/python3.6/site-packages/tensorflow/python/framework/function.py\u001b[0m in \u001b[0;36mcreate_op\u001b[0;34m(self, op_type, inputs, data_types, **kwargs)\u001b[0m\n\u001b[1;32m    701\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextra_args\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    702\u001b[0m     return super(_FuncGraph, self).create_op(op_type, inputs, data_types,\n\u001b[0;32m--> 703\u001b[0;31m                                              **kwargs)\n\u001b[0m\u001b[1;32m    704\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    705\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_add_tensor_and_parents\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/philip/anaconda2/envs/py3/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mcreate_op\u001b[0;34m(self, op_type, inputs, dtypes, input_types, name, attrs, op_def, compute_shapes, compute_device)\u001b[0m\n\u001b[1;32m   2956\u001b[0m         op_def=op_def)\n\u001b[1;32m   2957\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcompute_shapes\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2958\u001b[0;31m       \u001b[0mset_shapes_for_outputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mret\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2959\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_add_op\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mret\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2960\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_record_op_seen_by_control_dependencies\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mret\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/philip/anaconda2/envs/py3/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mset_shapes_for_outputs\u001b[0;34m(op)\u001b[0m\n\u001b[1;32m   2207\u001b[0m       \u001b[0mshape_func\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_call_cpp_shape_fn_and_require_op\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2208\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2209\u001b[0;31m   \u001b[0mshapes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mshape_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mop\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2210\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mshapes\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2211\u001b[0m     raise RuntimeError(\n",
      "\u001b[0;32m/home/philip/anaconda2/envs/py3/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mcall_with_requiring\u001b[0;34m(op)\u001b[0m\n\u001b[1;32m   2157\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2158\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mcall_with_requiring\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mop\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2159\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mcall_cpp_shape_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequire_shape_fn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2160\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2161\u001b[0m   \u001b[0m_call_cpp_shape_fn_and_require_op\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcall_with_requiring\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/philip/anaconda2/envs/py3/lib/python3.6/site-packages/tensorflow/python/framework/common_shapes.py\u001b[0m in \u001b[0;36mcall_cpp_shape_fn\u001b[0;34m(op, require_shape_fn)\u001b[0m\n\u001b[1;32m    625\u001b[0m     res = _call_cpp_shape_fn_impl(op, input_tensors_needed,\n\u001b[1;32m    626\u001b[0m                                   \u001b[0minput_tensors_as_shapes_needed\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 627\u001b[0;31m                                   require_shape_fn)\n\u001b[0m\u001b[1;32m    628\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mres\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    629\u001b[0m       \u001b[0;31m# Handles the case where _call_cpp_shape_fn_impl calls unknown_shape(op).\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/philip/anaconda2/envs/py3/lib/python3.6/site-packages/tensorflow/python/framework/common_shapes.py\u001b[0m in \u001b[0;36m_call_cpp_shape_fn_impl\u001b[0;34m(op, input_tensors_needed, input_tensors_as_shapes_needed, require_shape_fn)\u001b[0m\n\u001b[1;32m    689\u001b[0m       \u001b[0mmissing_shape_fn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    690\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 691\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    692\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    693\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mmissing_shape_fn\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Shape must be rank 1 but is rank 0 for 'StringSplit' (op: 'StringSplit') with input shapes: [], []."
     ]
    }
   ],
   "source": [
    "# data_s = binary_class_dataset_audio.map(get_silent_data).shuffle(buffer_size=320).batch(32)\n",
    "data_a = binary_class_dataset_silence.map(get_class_data).shuffle(buffer_size=320).batch(32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# from tensorflow.python.keras.layers import Conv2D,MaxPool2D,BatchNormalization,Input,Activation,MaxPool1D,Reshape, Bidirectional,Flatten,Dense\n",
    "# from tensorflow.python.keras.layers import GRU\n",
    "# from tensorflow.python.keras.layers import LSTM\n",
    "# from tensorflow.python.keras.models import Sequential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_12 (InputLayer)           (None, 16000, 1)     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_24 (Conv1D)              (None, 16000, 128)   65664       input_12[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_23 (BatchNo (None, 16000, 128)   512         conv1d_24[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_28 (MaxPooling1D) (None, 1599, 128)    0           batch_normalization_23[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_25 (Conv1D)              (None, 1599, 256)    8388864     max_pooling1d_28[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_24 (BatchNo (None, 1599, 256)    1024        conv1d_25[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_29 (MaxPooling1D) (None, 158, 256)     0           batch_normalization_24[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_20 (Bidirectional (None, 158, 256)     1052672     max_pooling1d_29[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_21 (Bidirectional (None, 158, 256)     1052672     bidirectional_20[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "permute_17 (Permute)            (None, 256, 158)     0           bidirectional_21[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "dense_9 (Dense)                 (None, 256, 158)     25122       permute_17[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "permute_18 (Permute)            (None, 158, 256)     0           dense_9[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "multiply_6 (Multiply)           (None, 158, 256)     0           bidirectional_21[0][0]           \n",
      "                                                                 permute_18[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_30 (MaxPooling1D) (None, 1, 256)       0           multiply_6[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "flatten_6 (Flatten)             (None, 256)          0           max_pooling1d_30[0][0]           \n",
      "==================================================================================================\n",
      "Total params: 10,586,530\n",
      "Trainable params: 10,585,762\n",
      "Non-trainable params: 768\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "input_layer = Input((16000,1))\n",
    "out = conv_1d_model(input_layer)\n",
    "from keras import Model\n",
    "model = Model(input_layer,out)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras import Sequential\n",
    "\n",
    "# def buile_1d_conv_model(class_num):\n",
    "#     model = Sequential()\n",
    "#     model.add(Conv1D(128,512,padding='same', input_shape=(16000,1),activation='relu',dilation_rate=4))\n",
    "#     model.add(BatchNormalization())\n",
    "#     model.add(MaxPool1D(pool_size=(20),strides=10))\n",
    "    \n",
    "#     model.add(Conv1D(256,256,padding='same', activation='relu',dilation_rate=4))\n",
    "#     model.add(BatchNormalization())\n",
    "#     model.add(MaxPool1D(pool_size=(20),strides=10))\n",
    "    \n",
    "#     model.add(Bidirectional(LSTM(256,return_sequences=True),merge_mode='ave'))\n",
    "#     model.add(Bidirectional(LSTM(256,return_sequences=True),merge_mode='ave'))\n",
    "    \n",
    "#     model.add(MaxPool1D(158))\n",
    "\n",
    "#     model.add(Flatten())\n",
    "\n",
    "#     return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = buile_1d_conv_model(1)\n",
    "model.add(Dense(1,activation='sigmoid'))\n",
    "model.compile(loss='binary_crossentropy',metrics=['binary_accuracy'],optimizer='sgd')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "next_batch_all = [i.make_one_shot_iterator().get_next() for i in [data_a,data_s]]\n",
    "next_seq_batch,next_label_batch = tf.concat([_[0] for _ in next_batch_all],0), tf.concat([_[1] for _ in next_batch_all],0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sess = tf.InteractiveSession()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      " - 4s - loss: 0.0365 - binary_accuracy: 0.9844\n",
      "Epoch 1/1\n",
      " - 4s - loss: 0.0135 - binary_accuracy: 1.0000\n",
      "Epoch 1/1\n",
      " - 4s - loss: 0.0678 - binary_accuracy: 0.9844\n",
      "Epoch 1/1\n",
      " - 4s - loss: 0.0423 - binary_accuracy: 0.9844\n",
      "Epoch 1/1\n",
      " - 4s - loss: 0.0652 - binary_accuracy: 0.9688\n",
      "Epoch 1/1\n",
      " - 4s - loss: 0.0566 - binary_accuracy: 0.9844\n",
      "Epoch 1/1\n",
      " - 4s - loss: 0.0322 - binary_accuracy: 1.0000\n",
      "Epoch 1/1\n",
      " - 4s - loss: 0.0387 - binary_accuracy: 0.9844\n",
      "Epoch 1/1\n",
      " - 4s - loss: 0.1268 - binary_accuracy: 0.9531\n",
      "Epoch 1/1\n",
      " - 4s - loss: 0.0439 - binary_accuracy: 0.9844\n",
      "Epoch 1/1\n",
      " - 4s - loss: 0.0638 - binary_accuracy: 0.9688\n",
      "Epoch 1/1\n",
      " - 4s - loss: 0.0646 - binary_accuracy: 0.9844\n",
      "Epoch 1/1\n",
      " - 4s - loss: 0.0475 - binary_accuracy: 0.9688\n",
      "Epoch 1/1\n",
      " - 4s - loss: 0.0473 - binary_accuracy: 0.9844\n",
      "Epoch 1/1\n",
      " - 4s - loss: 0.0210 - binary_accuracy: 1.0000\n",
      "Epoch 1/1\n",
      " - 4s - loss: 0.0201 - binary_accuracy: 1.0000\n",
      "Epoch 1/1\n",
      " - 4s - loss: 0.1242 - binary_accuracy: 0.9375\n",
      "Epoch 1/1\n",
      " - 4s - loss: 0.0367 - binary_accuracy: 1.0000\n",
      "Epoch 1/1\n",
      " - 4s - loss: 0.0255 - binary_accuracy: 1.0000\n",
      "Epoch 1/1\n",
      " - 4s - loss: 0.0813 - binary_accuracy: 0.9531\n",
      "Epoch 1/1\n",
      " - 4s - loss: 0.0758 - binary_accuracy: 0.9844\n",
      "Epoch 1/1\n",
      " - 4s - loss: 0.0370 - binary_accuracy: 0.9844\n",
      "Epoch 1/1\n",
      " - 4s - loss: 0.0408 - binary_accuracy: 0.9844\n",
      "Epoch 1/1\n",
      " - 4s - loss: 0.0692 - binary_accuracy: 0.9688\n",
      "Epoch 1/1\n",
      " - 4s - loss: 0.0309 - binary_accuracy: 1.0000\n",
      "Epoch 1/1\n",
      " - 4s - loss: 0.0266 - binary_accuracy: 1.0000\n",
      "Epoch 1/1\n",
      " - 4s - loss: 0.0385 - binary_accuracy: 1.0000\n",
      "Epoch 1/1\n",
      " - 4s - loss: 0.0143 - binary_accuracy: 1.0000\n",
      "Epoch 1/1\n",
      " - 4s - loss: 0.0411 - binary_accuracy: 0.9844\n",
      "Epoch 1/1\n",
      " - 4s - loss: 0.0584 - binary_accuracy: 0.9688\n",
      "Epoch 1/1\n",
      " - 4s - loss: 0.0359 - binary_accuracy: 1.0000\n",
      "Epoch 1/1\n",
      " - 4s - loss: 0.1189 - binary_accuracy: 0.9531\n",
      "Epoch 1/1\n",
      " - 4s - loss: 0.0743 - binary_accuracy: 0.9688\n",
      "Epoch 1/1\n",
      " - 3s - loss: 0.0531 - binary_accuracy: 0.9800\n",
      "Epoch 1/1\n",
      " - 4s - loss: 0.1855 - binary_accuracy: 0.9219\n",
      "Epoch 1/1\n",
      " - 4s - loss: 0.2222 - binary_accuracy: 0.9062\n",
      "Epoch 1/1\n",
      " - 4s - loss: 0.0868 - binary_accuracy: 0.9844\n",
      "Epoch 1/1\n",
      " - 4s - loss: 0.1332 - binary_accuracy: 0.9688\n",
      "Epoch 1/1\n",
      " - 4s - loss: 0.1303 - binary_accuracy: 0.9531\n",
      "Epoch 1/1\n",
      " - 4s - loss: 0.0546 - binary_accuracy: 0.9844\n",
      "Epoch 1/1\n",
      " - 4s - loss: 0.0557 - binary_accuracy: 0.9844\n",
      "Epoch 1/1\n",
      " - 4s - loss: 0.0628 - binary_accuracy: 1.0000\n",
      "Epoch 1/1\n",
      " - 4s - loss: 0.2065 - binary_accuracy: 0.9375\n",
      "Epoch 1/1\n",
      " - 4s - loss: 0.0984 - binary_accuracy: 0.9844\n",
      "Epoch 1/1\n",
      " - 4s - loss: 0.1199 - binary_accuracy: 0.9688\n",
      "Epoch 1/1\n",
      " - 4s - loss: 0.0753 - binary_accuracy: 0.9688\n",
      "Epoch 1/1\n",
      " - 4s - loss: 0.1671 - binary_accuracy: 0.9688\n",
      "Epoch 1/1\n",
      " - 4s - loss: 0.0778 - binary_accuracy: 0.9844\n",
      "Epoch 1/1\n",
      " - 4s - loss: 0.0331 - binary_accuracy: 1.0000\n",
      "Epoch 1/1\n",
      " - 4s - loss: 0.0272 - binary_accuracy: 1.0000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# for i in tqdm.tqdm_notebook(range(50)):\n",
    "#     seq,label = sess.run([next_seq_batch,next_label_batch])\n",
    "#     model.fit(np.expand_dims(seq,2),label,verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "seq,label = sess.run([next_seq_batch,next_label_batch])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(64,)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open(os.path.join(data_root,\"train/wrong.txt\"),'r') as f:\n",
    "    for line in sorted(f):\n",
    "        file,pre = (line[:-1]).split()\n",
    "        if file in s_list or file in w_list:\n",
    "            continue\n",
    "        label = file.split('/')[0]\n",
    "        if label == 'silence':\n",
    "            continue\n",
    "        dst = os.path.join(data_root,\"train/wrong/\",label+'/')\n",
    "        print(file)\n",
    "        if not os.path.isdir(dst):\n",
    "            os.mkdir(dst)\n",
    "        shutil.copy(os.path.join(data_root,\"train/audio/\",file.replace(\"png\",'wav')),dst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def delete_wrong_label(list_of_files):\n",
    "    for file in list_of_files:\n",
    "        filename = file.replace(\"png\",'wav')\n",
    "        label = filename.split('/')[0]\n",
    "        ori = os.path.join(data_root,\"train/audio/\",filename)\n",
    "        if not os.path.isfile(ori):\n",
    "            continue\n",
    "        else:\n",
    "            os.remove(ori)\n",
    "def move_to_silence(list_of_files):\n",
    "    for file in list_of_files:\n",
    "        filename = file.replace(\"png\",'wav')\n",
    "        label = filename.split('/')[0]\n",
    "        ori = os.path.join(data_root,\"train/audio/\",filename)\n",
    "        if not os.path.isfile(ori):\n",
    "            continue\n",
    "        dst = os.path.join(data_root,\"train/\",filename.replace(label+\"/\",\"silence/\"+label+\"_\"))\n",
    "        print(dst)\n",
    "        shutil.move(ori,dst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/philip/Files/Keyword_spot/train/silence/on_7fd25f7c_nohash_3.wav\n",
      "/home/philip/Files/Keyword_spot/train/silence/cat_1bc45db9_nohash_0.wav\n",
      "/home/philip/Files/Keyword_spot/train/silence/bird_3e7124ba_nohash_0.wav\n",
      "/home/philip/Files/Keyword_spot/train/silence/off_05b2db80_nohash_0.wav\n",
      "/home/philip/Files/Keyword_spot/train/silence/nine_05b2db80_nohash_0.wav\n",
      "/home/philip/Files/Keyword_spot/train/silence/house_5e3dde6b_nohash_0.wav\n",
      "/home/philip/Files/Keyword_spot/train/silence/sheila_7c1d8533_nohash_0.wav\n",
      "/home/philip/Files/Keyword_spot/train/silence/stop_7fd25f7c_nohash_1.wav\n",
      "/home/philip/Files/Keyword_spot/train/silence/dog_29fb33da_nohash_0.wav\n",
      "/home/philip/Files/Keyword_spot/train/silence/left_686d030b_nohash_1.wav\n",
      "/home/philip/Files/Keyword_spot/train/silence/marvin_712e4d58_nohash_0.wav\n",
      "/home/philip/Files/Keyword_spot/train/silence/nine_aff582a1_nohash_2.wav\n",
      "/home/philip/Files/Keyword_spot/train/silence/wow_cc6ee39b_nohash_0.wav\n",
      "/home/philip/Files/Keyword_spot/train/silence/stop_ce7a8e92_nohash_1.wav\n",
      "/home/philip/Files/Keyword_spot/train/silence/left_ced835d3_nohash_4.wav\n",
      "/home/philip/Files/Keyword_spot/train/silence/nine_fd395b74_nohash_1.wav\n",
      "/home/philip/Files/Keyword_spot/train/silence/bed_e96a5020_nohash_0.wav\n",
      "/home/philip/Files/Keyword_spot/train/silence/dog_6c429c7b_nohash_0.wav\n",
      "/home/philip/Files/Keyword_spot/train/silence/dog_b959cd0c_nohash_0.wav\n",
      "/home/philip/Files/Keyword_spot/train/silence/down_05b2db80_nohash_2.wav\n",
      "/home/philip/Files/Keyword_spot/train/silence/down_cd85758f_nohash_0.wav\n",
      "/home/philip/Files/Keyword_spot/train/silence/down_fd395b74_nohash_4.wav\n",
      "/home/philip/Files/Keyword_spot/train/silence/eight_712e4d58_nohash_2.wav\n",
      "/home/philip/Files/Keyword_spot/train/silence/eight_712e4d58_nohash_4.wav\n",
      "/home/philip/Files/Keyword_spot/train/silence/eight_c93d5e22_nohash_4.wav\n",
      "/home/philip/Files/Keyword_spot/train/silence/eight_e96a5020_nohash_1.wav\n",
      "/home/philip/Files/Keyword_spot/train/silence/eight_fd395b74_nohash_1.wav\n",
      "/home/philip/Files/Keyword_spot/train/silence/five_834f03fe_nohash_1.wav\n",
      "/home/philip/Files/Keyword_spot/train/silence/five_bdee441c_nohash_4.wav\n",
      "/home/philip/Files/Keyword_spot/train/silence/four_e5dadd24_nohash_0.wav\n",
      "/home/philip/Files/Keyword_spot/train/silence/four_fd395b74_nohash_3.wav\n",
      "/home/philip/Files/Keyword_spot/train/silence/happy_1fd85ee4_nohash_1.wav\n",
      "/home/philip/Files/Keyword_spot/train/silence/happy_1fd85ee4_nohash_2.wav\n",
      "/home/philip/Files/Keyword_spot/train/silence/happy_b959cd0c_nohash_0.wav\n",
      "/home/philip/Files/Keyword_spot/train/silence/house_e96a5020_nohash_0.wav\n",
      "/home/philip/Files/Keyword_spot/train/silence/house_fd395b74_nohash_0.wav\n",
      "/home/philip/Files/Keyword_spot/train/silence/left_e96a5020_nohash_2.wav\n",
      "/home/philip/Files/Keyword_spot/train/silence/marvin_3ea77ede_nohash_0.wav\n",
      "/home/philip/Files/Keyword_spot/train/silence/marvin_f8f60f59_nohash_0.wav\n",
      "/home/philip/Files/Keyword_spot/train/silence/nine_0132a06d_nohash_3.wav\n",
      "/home/philip/Files/Keyword_spot/train/silence/nine_3d53244b_nohash_3.wav\n",
      "/home/philip/Files/Keyword_spot/train/silence/nine_3d53244b_nohash_4.wav\n",
      "/home/philip/Files/Keyword_spot/train/silence/nine_c0445658_nohash_4.wav\n",
      "/home/philip/Files/Keyword_spot/train/silence/nine_ced835d3_nohash_1.wav\n",
      "/home/philip/Files/Keyword_spot/train/silence/nine_e96a5020_nohash_2.wav\n",
      "/home/philip/Files/Keyword_spot/train/silence/no_712e4d58_nohash_4.wav\n",
      "/home/philip/Files/Keyword_spot/train/silence/no_e96a5020_nohash_0.wav\n",
      "/home/philip/Files/Keyword_spot/train/silence/off_735845ab_nohash_2.wav\n",
      "/home/philip/Files/Keyword_spot/train/silence/off_e96a5020_nohash_1.wav\n",
      "/home/philip/Files/Keyword_spot/train/silence/off_fd395b74_nohash_1.wav\n",
      "/home/philip/Files/Keyword_spot/train/silence/on_92a9c5e6_nohash_3.wav\n",
      "/home/philip/Files/Keyword_spot/train/silence/on_d197e3ae_nohash_2.wav\n",
      "/home/philip/Files/Keyword_spot/train/silence/on_e96a5020_nohash_0.wav\n",
      "/home/philip/Files/Keyword_spot/train/silence/on_fd395b74_nohash_1.wav\n",
      "/home/philip/Files/Keyword_spot/train/silence/on_fd395b74_nohash_3.wav\n",
      "/home/philip/Files/Keyword_spot/train/silence/one_b959cd0c_nohash_3.wav\n",
      "/home/philip/Files/Keyword_spot/train/silence/one_e96a5020_nohash_2.wav\n",
      "/home/philip/Files/Keyword_spot/train/silence/right_190821dc_nohash_2.wav\n",
      "/home/philip/Files/Keyword_spot/train/silence/right_77def3ee_nohash_1.wav\n",
      "/home/philip/Files/Keyword_spot/train/silence/right_b959cd0c_nohash_4.wav\n",
      "/home/philip/Files/Keyword_spot/train/silence/right_be7a5b2d_nohash_3.wav\n",
      "/home/philip/Files/Keyword_spot/train/silence/right_ced835d3_nohash_0.wav\n",
      "/home/philip/Files/Keyword_spot/train/silence/right_e96a5020_nohash_0.wav\n",
      "/home/philip/Files/Keyword_spot/train/silence/right_e96a5020_nohash_1.wav\n",
      "/home/philip/Files/Keyword_spot/train/silence/right_e96a5020_nohash_2.wav\n",
      "/home/philip/Files/Keyword_spot/train/silence/right_e96a5020_nohash_4.wav\n",
      "/home/philip/Files/Keyword_spot/train/silence/seven_39a12648_nohash_4.wav\n",
      "/home/philip/Files/Keyword_spot/train/silence/seven_686d030b_nohash_4.wav\n",
      "/home/philip/Files/Keyword_spot/train/silence/seven_7846fd85_nohash_0.wav\n",
      "/home/philip/Files/Keyword_spot/train/silence/seven_c0445658_nohash_3.wav\n",
      "/home/philip/Files/Keyword_spot/train/silence/sheila_05b2db80_nohash_1.wav\n",
      "/home/philip/Files/Keyword_spot/train/silence/sheila_e53139ad_nohash_0.wav\n",
      "/home/philip/Files/Keyword_spot/train/silence/six_712e4d58_nohash_1.wav\n",
      "/home/philip/Files/Keyword_spot/train/silence/six_cc6ee39b_nohash_1.wav\n",
      "/home/philip/Files/Keyword_spot/train/silence/stop_b87bdb22_nohash_0.wav\n",
      "/home/philip/Files/Keyword_spot/train/silence/three_28ed6bc9_nohash_1.wav\n",
      "/home/philip/Files/Keyword_spot/train/silence/three_b959cd0c_nohash_0.wav\n",
      "/home/philip/Files/Keyword_spot/train/silence/three_dbb40d24_nohash_3.wav\n",
      "/home/philip/Files/Keyword_spot/train/silence/three_ee4a907f_nohash_1.wav\n",
      "/home/philip/Files/Keyword_spot/train/silence/three_fd395b74_nohash_2.wav\n",
      "/home/philip/Files/Keyword_spot/train/silence/tree_b959cd0c_nohash_0.wav\n",
      "/home/philip/Files/Keyword_spot/train/silence/tree_c0445658_nohash_0.wav\n",
      "/home/philip/Files/Keyword_spot/train/silence/two_fd395b74_nohash_4.wav\n",
      "/home/philip/Files/Keyword_spot/train/silence/up_40115b19_nohash_2.wav\n",
      "/home/philip/Files/Keyword_spot/train/silence/wow_e96a5020_nohash_0.wav\n",
      "/home/philip/Files/Keyword_spot/train/silence/wow_fd395b74_nohash_0.wav\n",
      "/home/philip/Files/Keyword_spot/train/silence/zero_b959cd0c_nohash_3.wav\n",
      "/home/philip/Files/Keyword_spot/train/silence/zero_e96a5020_nohash_1.wav\n",
      "/home/philip/Files/Keyword_spot/train/silence/zero_f8f60f59_nohash_0.wav\n",
      "/home/philip/Files/Keyword_spot/train/silence/zero_f8f60f59_nohash_3.wav\n",
      "/home/philip/Files/Keyword_spot/train/silence/zero_fd395b74_nohash_3.wav\n",
      "/home/philip/Files/Keyword_spot/train/silence/bird_e96a5020_nohash_0.wav\n",
      "/home/philip/Files/Keyword_spot/train/silence/dog_e96a5020_nohash_0.wav\n",
      "/home/philip/Files/Keyword_spot/train/silence/down_b959cd0c_nohash_4.wav\n",
      "/home/philip/Files/Keyword_spot/train/silence/down_e96a5020_nohash_0.wav\n",
      "/home/philip/Files/Keyword_spot/train/silence/down_ec201020_nohash_1.wav\n",
      "/home/philip/Files/Keyword_spot/train/silence/eight_735845ab_nohash_4.wav\n",
      "/home/philip/Files/Keyword_spot/train/silence/five_fd395b74_nohash_2.wav\n",
      "/home/philip/Files/Keyword_spot/train/silence/go_e5dadd24_nohash_0.wav\n",
      "/home/philip/Files/Keyword_spot/train/silence/marvin_e5dadd24_nohash_0.wav\n",
      "/home/philip/Files/Keyword_spot/train/silence/off_fd395b74_nohash_2.wav\n",
      "/home/philip/Files/Keyword_spot/train/silence/one_b959cd0c_nohash_0.wav\n",
      "/home/philip/Files/Keyword_spot/train/silence/right_735845ab_nohash_0.wav\n",
      "/home/philip/Files/Keyword_spot/train/silence/sheila_b9f46737_nohash_1.wav\n",
      "/home/philip/Files/Keyword_spot/train/silence/two_e96a5020_nohash_0.wav\n",
      "/home/philip/Files/Keyword_spot/train/silence/zero_ce7a8e92_nohash_2.wav\n",
      "/home/philip/Files/Keyword_spot/train/silence/bed_b959cd0c_nohash_0.wav\n",
      "/home/philip/Files/Keyword_spot/train/silence/bird_1bc45db9_nohash_0.wav\n",
      "/home/philip/Files/Keyword_spot/train/silence/bird_1bc45db9_nohash_1.wav\n",
      "/home/philip/Files/Keyword_spot/train/silence/bird_b959cd0c_nohash_0.wav\n",
      "/home/philip/Files/Keyword_spot/train/silence/bird_ced835d3_nohash_0.wav\n",
      "/home/philip/Files/Keyword_spot/train/silence/bird_fd395b74_nohash_0.wav\n",
      "/home/philip/Files/Keyword_spot/train/silence/cat_b959cd0c_nohash_0.wav\n",
      "/home/philip/Files/Keyword_spot/train/silence/cat_ced835d3_nohash_0.wav\n",
      "/home/philip/Files/Keyword_spot/train/silence/cat_dbb40d24_nohash_0.wav\n",
      "/home/philip/Files/Keyword_spot/train/silence/cat_e96a5020_nohash_0.wav\n",
      "/home/philip/Files/Keyword_spot/train/silence/cat_fd395b74_nohash_0.wav\n",
      "/home/philip/Files/Keyword_spot/train/silence/dog_ced835d3_nohash_0.wav\n",
      "/home/philip/Files/Keyword_spot/train/silence/dog_fd395b74_nohash_0.wav\n",
      "/home/philip/Files/Keyword_spot/train/silence/dog_3f2b358d_nohash_0.wav\n",
      "/home/philip/Files/Keyword_spot/train/silence/down_3bfd30e6_nohash_1.wav\n",
      "/home/philip/Files/Keyword_spot/train/silence/down_4a1e736b_nohash_4.wav\n",
      "/home/philip/Files/Keyword_spot/train/silence/down_888a0c49_nohash_3.wav\n",
      "/home/philip/Files/Keyword_spot/train/silence/down_b959cd0c_nohash_0.wav\n",
      "/home/philip/Files/Keyword_spot/train/silence/down_b959cd0c_nohash_1.wav\n",
      "/home/philip/Files/Keyword_spot/train/silence/down_b959cd0c_nohash_2.wav\n",
      "/home/philip/Files/Keyword_spot/train/silence/down_c0445658_nohash_4.wav\n",
      "/home/philip/Files/Keyword_spot/train/silence/down_d90b4138_nohash_2.wav\n",
      "/home/philip/Files/Keyword_spot/train/silence/down_e96a5020_nohash_1.wav\n",
      "/home/philip/Files/Keyword_spot/train/silence/down_e96a5020_nohash_2.wav\n",
      "/home/philip/Files/Keyword_spot/train/silence/down_fd395b74_nohash_1.wav\n",
      "/home/philip/Files/Keyword_spot/train/silence/eight_122c5aa7_nohash_1.wav\n",
      "/home/philip/Files/Keyword_spot/train/silence/eight_2b3f509b_nohash_0.wav\n",
      "/home/philip/Files/Keyword_spot/train/silence/eight_3bfd30e6_nohash_4.wav\n",
      "/home/philip/Files/Keyword_spot/train/silence/eight_3c257192_nohash_1.wav\n",
      "/home/philip/Files/Keyword_spot/train/silence/eight_53eb0a88_nohash_1.wav\n",
      "/home/philip/Files/Keyword_spot/train/silence/eight_61e50f62_nohash_0.wav\n",
      "/home/philip/Files/Keyword_spot/train/silence/eight_712e4d58_nohash_1.wav\n",
      "/home/philip/Files/Keyword_spot/train/silence/eight_7fd25f7c_nohash_2.wav\n",
      "/home/philip/Files/Keyword_spot/train/silence/eight_951cac20_nohash_0.wav\n",
      "/home/philip/Files/Keyword_spot/train/silence/eight_b959cd0c_nohash_1.wav\n",
      "/home/philip/Files/Keyword_spot/train/silence/eight_b959cd0c_nohash_2.wav\n",
      "/home/philip/Files/Keyword_spot/train/silence/eight_b959cd0c_nohash_3.wav\n",
      "/home/philip/Files/Keyword_spot/train/silence/eight_b959cd0c_nohash_4.wav\n",
      "/home/philip/Files/Keyword_spot/train/silence/eight_ced835d3_nohash_1.wav\n",
      "/home/philip/Files/Keyword_spot/train/silence/eight_ced835d3_nohash_3.wav\n",
      "/home/philip/Files/Keyword_spot/train/silence/eight_ced835d3_nohash_4.wav\n",
      "/home/philip/Files/Keyword_spot/train/silence/eight_e96a5020_nohash_0.wav\n",
      "/home/philip/Files/Keyword_spot/train/silence/eight_f5733968_nohash_2.wav\n",
      "/home/philip/Files/Keyword_spot/train/silence/eight_f8f60f59_nohash_2.wav\n",
      "/home/philip/Files/Keyword_spot/train/silence/eight_fd395b74_nohash_3.wav\n",
      "/home/philip/Files/Keyword_spot/train/silence/five_122c5aa7_nohash_1.wav\n",
      "/home/philip/Files/Keyword_spot/train/silence/five_3f2b358d_nohash_2.wav\n",
      "/home/philip/Files/Keyword_spot/train/silence/five_5fadb538_nohash_3.wav\n",
      "/home/philip/Files/Keyword_spot/train/silence/five_763188c4_nohash_2.wav\n",
      "/home/philip/Files/Keyword_spot/train/silence/five_a6d586b7_nohash_0.wav\n",
      "/home/philip/Files/Keyword_spot/train/silence/five_b959cd0c_nohash_0.wav\n",
      "/home/philip/Files/Keyword_spot/train/silence/five_b959cd0c_nohash_2.wav\n",
      "/home/philip/Files/Keyword_spot/train/silence/five_b959cd0c_nohash_3.wav\n",
      "/home/philip/Files/Keyword_spot/train/silence/five_b959cd0c_nohash_4.wav\n",
      "/home/philip/Files/Keyword_spot/train/silence/five_b9f46737_nohash_2.wav\n",
      "/home/philip/Files/Keyword_spot/train/silence/five_ced835d3_nohash_0.wav\n",
      "/home/philip/Files/Keyword_spot/train/silence/five_ced835d3_nohash_3.wav\n",
      "/home/philip/Files/Keyword_spot/train/silence/five_d197e3ae_nohash_1.wav\n",
      "/home/philip/Files/Keyword_spot/train/silence/five_e96a5020_nohash_0.wav\n",
      "/home/philip/Files/Keyword_spot/train/silence/five_e96a5020_nohash_1.wav\n",
      "/home/philip/Files/Keyword_spot/train/silence/five_e96a5020_nohash_2.wav\n",
      "/home/philip/Files/Keyword_spot/train/silence/five_fd395b74_nohash_0.wav\n",
      "/home/philip/Files/Keyword_spot/train/silence/four_0137b3f4_nohash_3.wav\n",
      "/home/philip/Files/Keyword_spot/train/silence/four_190821dc_nohash_4.wav\n",
      "/home/philip/Files/Keyword_spot/train/silence/four_51055bda_nohash_3.wav\n",
      "/home/philip/Files/Keyword_spot/train/silence/four_611d2b50_nohash_1.wav\n",
      "/home/philip/Files/Keyword_spot/train/silence/four_6727b579_nohash_0.wav\n",
      "/home/philip/Files/Keyword_spot/train/silence/four_ad63d93c_nohash_1.wav\n",
      "/home/philip/Files/Keyword_spot/train/silence/four_b959cd0c_nohash_0.wav\n",
      "/home/philip/Files/Keyword_spot/train/silence/four_b959cd0c_nohash_2.wav\n",
      "/home/philip/Files/Keyword_spot/train/silence/four_b959cd0c_nohash_4.wav\n",
      "/home/philip/Files/Keyword_spot/train/silence/four_c0445658_nohash_1.wav\n",
      "/home/philip/Files/Keyword_spot/train/silence/four_c93d5e22_nohash_0.wav\n",
      "/home/philip/Files/Keyword_spot/train/silence/four_ced835d3_nohash_0.wav\n",
      "/home/philip/Files/Keyword_spot/train/silence/four_d197e3ae_nohash_4.wav\n",
      "/home/philip/Files/Keyword_spot/train/silence/four_e53139ad_nohash_0.wav\n",
      "/home/philip/Files/Keyword_spot/train/silence/four_e96a5020_nohash_0.wav\n",
      "/home/philip/Files/Keyword_spot/train/silence/four_e96a5020_nohash_1.wav\n",
      "/home/philip/Files/Keyword_spot/train/silence/go_1bc45db9_nohash_0.wav\n",
      "/home/philip/Files/Keyword_spot/train/silence/go_1bc45db9_nohash_1.wav\n",
      "/home/philip/Files/Keyword_spot/train/silence/go_7fd25f7c_nohash_4.wav\n",
      "/home/philip/Files/Keyword_spot/train/silence/go_15c563d7_nohash_0.wav\n",
      "/home/philip/Files/Keyword_spot/train/silence/go_92a9c5e6_nohash_4.wav\n",
      "/home/philip/Files/Keyword_spot/train/silence/go_611d2b50_nohash_2.wav\n",
      "/home/philip/Files/Keyword_spot/train/silence/go_712e4d58_nohash_2.wav\n",
      "/home/philip/Files/Keyword_spot/train/silence/go_b959cd0c_nohash_0.wav\n",
      "/home/philip/Files/Keyword_spot/train/silence/go_b959cd0c_nohash_1.wav\n",
      "/home/philip/Files/Keyword_spot/train/silence/go_b959cd0c_nohash_3.wav\n",
      "/home/philip/Files/Keyword_spot/train/silence/go_c0445658_nohash_3.wav\n",
      "/home/philip/Files/Keyword_spot/train/silence/go_d90b4138_nohash_4.wav\n",
      "/home/philip/Files/Keyword_spot/train/silence/go_e96a5020_nohash_0.wav\n",
      "/home/philip/Files/Keyword_spot/train/silence/go_e96a5020_nohash_1.wav\n",
      "/home/philip/Files/Keyword_spot/train/silence/go_f8f60f59_nohash_0.wav\n",
      "/home/philip/Files/Keyword_spot/train/silence/go_f8f60f59_nohash_2.wav\n",
      "/home/philip/Files/Keyword_spot/train/silence/happy_ced835d3_nohash_0.wav\n",
      "/home/philip/Files/Keyword_spot/train/silence/happy_1fd85ee4_nohash_0.wav\n",
      "/home/philip/Files/Keyword_spot/train/silence/happy_2da58b32_nohash_0.wav\n",
      "/home/philip/Files/Keyword_spot/train/silence/house_ced835d3_nohash_0.wav\n",
      "/home/philip/Files/Keyword_spot/train/silence/left_2b3f509b_nohash_1.wav\n",
      "/home/philip/Files/Keyword_spot/train/silence/left_3bfd30e6_nohash_0.wav\n",
      "/home/philip/Files/Keyword_spot/train/silence/left_8f4c551f_nohash_3.wav\n",
      "/home/philip/Files/Keyword_spot/train/silence/left_712e4d58_nohash_2.wav\n",
      "/home/philip/Files/Keyword_spot/train/silence/left_a6d586b7_nohash_4.wav\n",
      "/home/philip/Files/Keyword_spot/train/silence/left_b959cd0c_nohash_1.wav\n",
      "/home/philip/Files/Keyword_spot/train/silence/left_b959cd0c_nohash_2.wav\n",
      "/home/philip/Files/Keyword_spot/train/silence/left_b959cd0c_nohash_4.wav\n",
      "/home/philip/Files/Keyword_spot/train/silence/left_be7a5b2d_nohash_0.wav\n",
      "/home/philip/Files/Keyword_spot/train/silence/left_cd85758f_nohash_2.wav\n",
      "/home/philip/Files/Keyword_spot/train/silence/left_e53139ad_nohash_3.wav\n",
      "/home/philip/Files/Keyword_spot/train/silence/left_e96a5020_nohash_1.wav\n",
      "/home/philip/Files/Keyword_spot/train/silence/left_fd395b74_nohash_1.wav\n",
      "/home/philip/Files/Keyword_spot/train/silence/marvin_24ad3ebe_nohash_1.wav\n",
      "/home/philip/Files/Keyword_spot/train/silence/marvin_563aa4e6_nohash_0.wav\n",
      "/home/philip/Files/Keyword_spot/train/silence/marvin_a6d586b7_nohash_0.wav\n",
      "/home/philip/Files/Keyword_spot/train/silence/marvin_b959cd0c_nohash_0.wav\n",
      "/home/philip/Files/Keyword_spot/train/silence/marvin_ced835d3_nohash_0.wav\n",
      "/home/philip/Files/Keyword_spot/train/silence/marvin_fd395b74_nohash_0.wav\n",
      "/home/philip/Files/Keyword_spot/train/silence/nine_1fd85ee4_nohash_1.wav\n",
      "/home/philip/Files/Keyword_spot/train/silence/nine_2b3f509b_nohash_0.wav\n",
      "/home/philip/Files/Keyword_spot/train/silence/nine_36050ef3_nohash_0.wav\n",
      "/home/philip/Files/Keyword_spot/train/silence/nine_3f2b358d_nohash_0.wav\n",
      "/home/philip/Files/Keyword_spot/train/silence/nine_3f2b358d_nohash_1.wav\n",
      "/home/philip/Files/Keyword_spot/train/silence/nine_b959cd0c_nohash_0.wav\n",
      "/home/philip/Files/Keyword_spot/train/silence/nine_ced835d3_nohash_2.wav\n",
      "/home/philip/Files/Keyword_spot/train/silence/nine_ced835d3_nohash_4.wav\n",
      "/home/philip/Files/Keyword_spot/train/silence/nine_dbb40d24_nohash_1.wav\n",
      "/home/philip/Files/Keyword_spot/train/silence/nine_e0315cf6_nohash_0.wav\n",
      "/home/philip/Files/Keyword_spot/train/silence/nine_e96a5020_nohash_0.wav\n",
      "/home/philip/Files/Keyword_spot/train/silence/nine_e96a5020_nohash_1.wav\n",
      "/home/philip/Files/Keyword_spot/train/silence/nine_f17be97f_nohash_4.wav\n",
      "/home/philip/Files/Keyword_spot/train/silence/nine_f8f60f59_nohash_4.wav\n",
      "/home/philip/Files/Keyword_spot/train/silence/nine_fd395b74_nohash_0.wav\n",
      "/home/philip/Files/Keyword_spot/train/silence/nine_fd395b74_nohash_2.wav\n",
      "/home/philip/Files/Keyword_spot/train/silence/no_5c39594f_nohash_1.wav\n",
      "/home/philip/Files/Keyword_spot/train/silence/no_b959cd0c_nohash_3.wav\n",
      "/home/philip/Files/Keyword_spot/train/silence/no_e96a5020_nohash_2.wav\n",
      "/home/philip/Files/Keyword_spot/train/silence/no_f8f60f59_nohash_0.wav\n",
      "/home/philip/Files/Keyword_spot/train/silence/no_fd395b74_nohash_1.wav\n",
      "/home/philip/Files/Keyword_spot/train/silence/no_fd395b74_nohash_3.wav\n",
      "/home/philip/Files/Keyword_spot/train/silence/off_2b3f509b_nohash_0.wav\n",
      "/home/philip/Files/Keyword_spot/train/silence/off_36050ef3_nohash_4.wav\n",
      "/home/philip/Files/Keyword_spot/train/silence/off_38d78313_nohash_0.wav\n",
      "/home/philip/Files/Keyword_spot/train/silence/off_3d53244b_nohash_4.wav\n",
      "/home/philip/Files/Keyword_spot/train/silence/off_65f2531f_nohash_0.wav\n",
      "/home/philip/Files/Keyword_spot/train/silence/off_6727b579_nohash_2.wav\n",
      "/home/philip/Files/Keyword_spot/train/silence/off_92a9c5e6_nohash_1.wav\n",
      "/home/philip/Files/Keyword_spot/train/silence/off_aff582a1_nohash_2.wav\n",
      "/home/philip/Files/Keyword_spot/train/silence/off_b9f46737_nohash_2.wav\n",
      "/home/philip/Files/Keyword_spot/train/silence/off_bab36420_nohash_0.wav\n",
      "/home/philip/Files/Keyword_spot/train/silence/off_c93d5e22_nohash_1.wav\n",
      "/home/philip/Files/Keyword_spot/train/silence/off_ec201020_nohash_3.wav\n",
      "/home/philip/Files/Keyword_spot/train/silence/off_f17be97f_nohash_2.wav\n",
      "/home/philip/Files/Keyword_spot/train/silence/off_f8f60f59_nohash_1.wav\n",
      "/home/philip/Files/Keyword_spot/train/silence/off_f953e1af_nohash_2.wav\n",
      "/home/philip/Files/Keyword_spot/train/silence/off_fd395b74_nohash_0.wav\n",
      "/home/philip/Files/Keyword_spot/train/silence/off_fd395b74_nohash_3.wav\n",
      "/home/philip/Files/Keyword_spot/train/silence/off_fd395b74_nohash_4.wav\n",
      "/home/philip/Files/Keyword_spot/train/silence/on_099d52ad_nohash_3.wav\n",
      "/home/philip/Files/Keyword_spot/train/silence/on_6c429c7b_nohash_0.wav\n",
      "/home/philip/Files/Keyword_spot/train/silence/on_712e4d58_nohash_4.wav\n",
      "/home/philip/Files/Keyword_spot/train/silence/on_763188c4_nohash_2.wav\n",
      "/home/philip/Files/Keyword_spot/train/silence/on_a6d586b7_nohash_4.wav\n",
      "/home/philip/Files/Keyword_spot/train/silence/on_b87bdb22_nohash_0.wav\n",
      "/home/philip/Files/Keyword_spot/train/silence/on_b959cd0c_nohash_0.wav\n",
      "/home/philip/Files/Keyword_spot/train/silence/on_b959cd0c_nohash_1.wav\n",
      "/home/philip/Files/Keyword_spot/train/silence/on_b959cd0c_nohash_3.wav\n",
      "/home/philip/Files/Keyword_spot/train/silence/on_ced835d3_nohash_3.wav\n",
      "/home/philip/Files/Keyword_spot/train/silence/on_dea820ce_nohash_2.wav\n",
      "/home/philip/Files/Keyword_spot/train/silence/on_e5dadd24_nohash_0.wav\n",
      "/home/philip/Files/Keyword_spot/train/silence/on_e96a5020_nohash_1.wav\n",
      "/home/philip/Files/Keyword_spot/train/silence/on_e96a5020_nohash_2.wav\n",
      "/home/philip/Files/Keyword_spot/train/silence/on_ec201020_nohash_1.wav\n",
      "/home/philip/Files/Keyword_spot/train/silence/on_ec201020_nohash_4.wav\n",
      "/home/philip/Files/Keyword_spot/train/silence/on_f953e1af_nohash_1.wav\n",
      "/home/philip/Files/Keyword_spot/train/silence/one_7fd25f7c_nohash_3.wav\n",
      "/home/philip/Files/Keyword_spot/train/silence/one_35d1b6ee_nohash_4.wav\n",
      "/home/philip/Files/Keyword_spot/train/silence/one_190821dc_nohash_4.wav\n",
      "/home/philip/Files/Keyword_spot/train/silence/one_763188c4_nohash_2.wav\n",
      "/home/philip/Files/Keyword_spot/train/silence/one_ced835d3_nohash_1.wav\n",
      "/home/philip/Files/Keyword_spot/train/silence/one_ced835d3_nohash_3.wav\n",
      "/home/philip/Files/Keyword_spot/train/silence/one_ced835d3_nohash_4.wav\n",
      "/home/philip/Files/Keyword_spot/train/silence/one_d197e3ae_nohash_4.wav\n",
      "/home/philip/Files/Keyword_spot/train/silence/one_dea820ce_nohash_1.wav\n",
      "/home/philip/Files/Keyword_spot/train/silence/one_e96a5020_nohash_0.wav\n",
      "/home/philip/Files/Keyword_spot/train/silence/one_e96a5020_nohash_1.wav\n",
      "/home/philip/Files/Keyword_spot/train/silence/one_f8f60f59_nohash_1.wav\n",
      "/home/philip/Files/Keyword_spot/train/silence/one_f8f60f59_nohash_4.wav\n",
      "/home/philip/Files/Keyword_spot/train/silence/one_fd395b74_nohash_1.wav\n",
      "/home/philip/Files/Keyword_spot/train/silence/one_fd395b74_nohash_4.wav\n",
      "/home/philip/Files/Keyword_spot/train/silence/right_3f2b358d_nohash_0.wav\n",
      "/home/philip/Files/Keyword_spot/train/silence/right_8f4c551f_nohash_0.wav\n",
      "/home/philip/Files/Keyword_spot/train/silence/right_29fb33da_nohash_4.wav\n",
      "/home/philip/Files/Keyword_spot/train/silence/right_122c5aa7_nohash_4.wav\n",
      "/home/philip/Files/Keyword_spot/train/silence/right_264f471d_nohash_4.wav\n",
      "/home/philip/Files/Keyword_spot/train/silence/right_563aa4e6_nohash_1.wav\n",
      "/home/philip/Files/Keyword_spot/train/silence/right_a6d586b7_nohash_1.wav\n",
      "/home/philip/Files/Keyword_spot/train/silence/right_b7a0754f_nohash_3.wav\n",
      "/home/philip/Files/Keyword_spot/train/silence/right_b959cd0c_nohash_1.wav\n",
      "/home/philip/Files/Keyword_spot/train/silence/right_b959cd0c_nohash_2.wav\n",
      "/home/philip/Files/Keyword_spot/train/silence/right_b959cd0c_nohash_3.wav\n",
      "/home/philip/Files/Keyword_spot/train/silence/right_ced835d3_nohash_1.wav\n",
      "/home/philip/Files/Keyword_spot/train/silence/right_ced835d3_nohash_2.wav\n",
      "/home/philip/Files/Keyword_spot/train/silence/right_e96a5020_nohash_3.wav\n",
      "/home/philip/Files/Keyword_spot/train/silence/right_ec201020_nohash_0.wav\n",
      "/home/philip/Files/Keyword_spot/train/silence/right_fd395b74_nohash_0.wav\n",
      "/home/philip/Files/Keyword_spot/train/silence/seven_099d52ad_nohash_4.wav\n",
      "/home/philip/Files/Keyword_spot/train/silence/seven_38d78313_nohash_2.wav\n",
      "/home/philip/Files/Keyword_spot/train/silence/seven_3f2b358d_nohash_0.wav\n",
      "/home/philip/Files/Keyword_spot/train/silence/seven_5fadb538_nohash_4.wav\n",
      "/home/philip/Files/Keyword_spot/train/silence/seven_712e4d58_nohash_2.wav\n",
      "/home/philip/Files/Keyword_spot/train/silence/seven_8f4c551f_nohash_4.wav\n",
      "/home/philip/Files/Keyword_spot/train/silence/seven_b87bdb22_nohash_0.wav\n",
      "/home/philip/Files/Keyword_spot/train/silence/seven_b959cd0c_nohash_0.wav\n",
      "/home/philip/Files/Keyword_spot/train/silence/seven_b959cd0c_nohash_2.wav\n",
      "/home/philip/Files/Keyword_spot/train/silence/seven_b959cd0c_nohash_3.wav\n",
      "/home/philip/Files/Keyword_spot/train/silence/seven_b959cd0c_nohash_4.wav\n",
      "/home/philip/Files/Keyword_spot/train/silence/seven_e96a5020_nohash_0.wav\n",
      "/home/philip/Files/Keyword_spot/train/silence/seven_e96a5020_nohash_1.wav\n",
      "/home/philip/Files/Keyword_spot/train/silence/seven_eb3f7d82_nohash_3.wav\n",
      "/home/philip/Files/Keyword_spot/train/silence/seven_fd395b74_nohash_0.wav\n",
      "/home/philip/Files/Keyword_spot/train/silence/seven_fd395b74_nohash_1.wav\n",
      "/home/philip/Files/Keyword_spot/train/silence/seven_fd395b74_nohash_3.wav\n",
      "/home/philip/Files/Keyword_spot/train/silence/sheila_264f471d_nohash_0.wav\n",
      "/home/philip/Files/Keyword_spot/train/silence/sheila_49af4432_nohash_0.wav\n",
      "/home/philip/Files/Keyword_spot/train/silence/sheila_563aa4e6_nohash_0.wav\n",
      "/home/philip/Files/Keyword_spot/train/silence/sheila_a6d586b7_nohash_0.wav\n",
      "/home/philip/Files/Keyword_spot/train/silence/sheila_b959cd0c_nohash_0.wav\n",
      "/home/philip/Files/Keyword_spot/train/silence/sheila_b9f46737_nohash_0.wav\n",
      "/home/philip/Files/Keyword_spot/train/silence/sheila_e1469561_nohash_0.wav\n",
      "/home/philip/Files/Keyword_spot/train/silence/sheila_fd395b74_nohash_0.wav\n",
      "/home/philip/Files/Keyword_spot/train/silence/six_190821dc_nohash_4.wav\n",
      "/home/philip/Files/Keyword_spot/train/silence/six_611d2b50_nohash_0.wav\n",
      "/home/philip/Files/Keyword_spot/train/silence/six_712e4d58_nohash_0.wav\n",
      "/home/philip/Files/Keyword_spot/train/silence/six_7e7f0ed6_nohash_1.wav\n",
      "/home/philip/Files/Keyword_spot/train/silence/six_92a9c5e6_nohash_2.wav\n",
      "/home/philip/Files/Keyword_spot/train/silence/six_b959cd0c_nohash_0.wav\n",
      "/home/philip/Files/Keyword_spot/train/silence/six_b959cd0c_nohash_4.wav\n",
      "/home/philip/Files/Keyword_spot/train/silence/six_ced835d3_nohash_3.wav\n",
      "/home/philip/Files/Keyword_spot/train/silence/six_e96a5020_nohash_0.wav\n",
      "/home/philip/Files/Keyword_spot/train/silence/six_e96a5020_nohash_1.wav\n",
      "/home/philip/Files/Keyword_spot/train/silence/six_e96a5020_nohash_2.wav\n",
      "/home/philip/Files/Keyword_spot/train/silence/six_f8f60f59_nohash_0.wav\n",
      "/home/philip/Files/Keyword_spot/train/silence/six_fd395b74_nohash_2.wav\n",
      "/home/philip/Files/Keyword_spot/train/silence/six_fd395b74_nohash_4.wav\n",
      "/home/philip/Files/Keyword_spot/train/silence/stop_190821dc_nohash_3.wav\n",
      "/home/philip/Files/Keyword_spot/train/silence/stop_1fd85ee4_nohash_0.wav\n",
      "/home/philip/Files/Keyword_spot/train/silence/stop_3df9a3d4_nohash_0.wav\n",
      "/home/philip/Files/Keyword_spot/train/silence/stop_9ff2d2f4_nohash_1.wav\n",
      "/home/philip/Files/Keyword_spot/train/silence/stop_aff582a1_nohash_4.wav\n",
      "/home/philip/Files/Keyword_spot/train/silence/stop_b9515bf3_nohash_2.wav\n",
      "/home/philip/Files/Keyword_spot/train/silence/stop_b959cd0c_nohash_0.wav\n",
      "/home/philip/Files/Keyword_spot/train/silence/stop_b959cd0c_nohash_4.wav\n",
      "/home/philip/Files/Keyword_spot/train/silence/stop_d9462202_nohash_0.wav\n",
      "/home/philip/Files/Keyword_spot/train/silence/stop_e96a5020_nohash_0.wav\n",
      "/home/philip/Files/Keyword_spot/train/silence/stop_e96a5020_nohash_1.wav\n",
      "/home/philip/Files/Keyword_spot/train/silence/stop_eb3f7d82_nohash_4.wav\n",
      "/home/philip/Files/Keyword_spot/train/silence/stop_ec201020_nohash_3.wav\n",
      "/home/philip/Files/Keyword_spot/train/silence/stop_f8f60f59_nohash_0.wav\n",
      "/home/philip/Files/Keyword_spot/train/silence/stop_f8f60f59_nohash_1.wav\n",
      "/home/philip/Files/Keyword_spot/train/silence/stop_fd395b74_nohash_0.wav\n",
      "/home/philip/Files/Keyword_spot/train/silence/stop_fd395b74_nohash_2.wav\n",
      "/home/philip/Files/Keyword_spot/train/silence/three_0132a06d_nohash_1.wav\n",
      "/home/philip/Files/Keyword_spot/train/silence/three_2da58b32_nohash_1.wav\n",
      "/home/philip/Files/Keyword_spot/train/silence/three_35d1b6ee_nohash_3.wav\n",
      "/home/philip/Files/Keyword_spot/train/silence/three_39999a0f_nohash_0.wav\n",
      "/home/philip/Files/Keyword_spot/train/silence/three_3bfd30e6_nohash_4.wav\n",
      "/home/philip/Files/Keyword_spot/train/silence/three_3f2b358d_nohash_2.wav\n",
      "/home/philip/Files/Keyword_spot/train/silence/three_611d2b50_nohash_2.wav\n",
      "/home/philip/Files/Keyword_spot/train/silence/three_611d2b50_nohash_3.wav\n",
      "/home/philip/Files/Keyword_spot/train/silence/three_611d2b50_nohash_4.wav\n",
      "/home/philip/Files/Keyword_spot/train/silence/three_6727b579_nohash_4.wav\n",
      "/home/philip/Files/Keyword_spot/train/silence/three_686d030b_nohash_4.wav\n",
      "/home/philip/Files/Keyword_spot/train/silence/three_b959cd0c_nohash_1.wav\n",
      "/home/philip/Files/Keyword_spot/train/silence/three_b959cd0c_nohash_2.wav\n",
      "/home/philip/Files/Keyword_spot/train/silence/three_b959cd0c_nohash_3.wav\n",
      "/home/philip/Files/Keyword_spot/train/silence/three_b959cd0c_nohash_4.wav\n",
      "/home/philip/Files/Keyword_spot/train/silence/three_d197e3ae_nohash_1.wav\n",
      "/home/philip/Files/Keyword_spot/train/silence/three_e41a903b_nohash_4.wav\n",
      "/home/philip/Files/Keyword_spot/train/silence/three_e53139ad_nohash_0.wav\n",
      "/home/philip/Files/Keyword_spot/train/silence/three_e53139ad_nohash_2.wav\n",
      "/home/philip/Files/Keyword_spot/train/silence/three_f17be97f_nohash_1.wav\n",
      "/home/philip/Files/Keyword_spot/train/silence/three_f8f60f59_nohash_3.wav\n",
      "/home/philip/Files/Keyword_spot/train/silence/tree_3bc21161_nohash_0.wav\n",
      "/home/philip/Files/Keyword_spot/train/silence/tree_3ea77ede_nohash_0.wav\n",
      "/home/philip/Files/Keyword_spot/train/silence/tree_70a00e98_nohash_0.wav\n",
      "/home/philip/Files/Keyword_spot/train/silence/tree_264f471d_nohash_0.wav\n",
      "/home/philip/Files/Keyword_spot/train/silence/tree_fd395b74_nohash_0.wav\n",
      "/home/philip/Files/Keyword_spot/train/silence/two_3f2b358d_nohash_0.wav\n",
      "/home/philip/Files/Keyword_spot/train/silence/two_9aa21fa9_nohash_3.wav\n",
      "/home/philip/Files/Keyword_spot/train/silence/two_712e4d58_nohash_3.wav\n",
      "/home/philip/Files/Keyword_spot/train/silence/two_51055bda_nohash_4.wav\n",
      "/home/philip/Files/Keyword_spot/train/silence/two_b9f46737_nohash_4.wav\n",
      "/home/philip/Files/Keyword_spot/train/silence/two_b959cd0c_nohash_0.wav\n",
      "/home/philip/Files/Keyword_spot/train/silence/two_b959cd0c_nohash_1.wav\n",
      "/home/philip/Files/Keyword_spot/train/silence/two_b959cd0c_nohash_2.wav\n",
      "/home/philip/Files/Keyword_spot/train/silence/two_b959cd0c_nohash_3.wav\n",
      "/home/philip/Files/Keyword_spot/train/silence/two_b959cd0c_nohash_4.wav\n",
      "/home/philip/Files/Keyword_spot/train/silence/two_ced835d3_nohash_0.wav\n",
      "/home/philip/Files/Keyword_spot/train/silence/two_ced835d3_nohash_2.wav\n",
      "/home/philip/Files/Keyword_spot/train/silence/two_d197e3ae_nohash_2.wav\n",
      "/home/philip/Files/Keyword_spot/train/silence/two_e96a5020_nohash_1.wav\n",
      "/home/philip/Files/Keyword_spot/train/silence/two_ee4a907f_nohash_0.wav\n",
      "/home/philip/Files/Keyword_spot/train/silence/two_f17be97f_nohash_0.wav\n",
      "/home/philip/Files/Keyword_spot/train/silence/two_f8f60f59_nohash_1.wav\n",
      "/home/philip/Files/Keyword_spot/train/silence/two_fd395b74_nohash_0.wav\n",
      "/home/philip/Files/Keyword_spot/train/silence/two_fd395b74_nohash_1.wav\n",
      "/home/philip/Files/Keyword_spot/train/silence/up_92a9c5e6_nohash_3.wav\n",
      "/home/philip/Files/Keyword_spot/train/silence/up_122c5aa7_nohash_4.wav\n",
      "/home/philip/Files/Keyword_spot/train/silence/up_8830e17f_nohash_3.wav\n",
      "/home/philip/Files/Keyword_spot/train/silence/up_51055bda_nohash_3.wav\n",
      "/home/philip/Files/Keyword_spot/train/silence/up_ad63d93c_nohash_0.wav\n",
      "/home/philip/Files/Keyword_spot/train/silence/up_b9f46737_nohash_3.wav\n",
      "/home/philip/Files/Keyword_spot/train/silence/up_b9f46737_nohash_5.wav\n",
      "/home/philip/Files/Keyword_spot/train/silence/up_bdee441c_nohash_3.wav\n",
      "/home/philip/Files/Keyword_spot/train/silence/up_ced835d3_nohash_4.wav\n",
      "/home/philip/Files/Keyword_spot/train/silence/up_e96a5020_nohash_0.wav\n",
      "/home/philip/Files/Keyword_spot/train/silence/up_e96a5020_nohash_1.wav\n",
      "/home/philip/Files/Keyword_spot/train/silence/up_f8f60f59_nohash_3.wav\n",
      "/home/philip/Files/Keyword_spot/train/silence/up_f17be97f_nohash_4.wav\n",
      "/home/philip/Files/Keyword_spot/train/silence/up_fd395b74_nohash_1.wav\n",
      "/home/philip/Files/Keyword_spot/train/silence/up_fd395b74_nohash_2.wav\n",
      "/home/philip/Files/Keyword_spot/train/silence/up_fd395b74_nohash_3.wav\n",
      "/home/philip/Files/Keyword_spot/train/silence/wow_712e4d58_nohash_0.wav\n",
      "/home/philip/Files/Keyword_spot/train/silence/wow_b959cd0c_nohash_0.wav\n",
      "/home/philip/Files/Keyword_spot/train/silence/wow_c0445658_nohash_0.wav\n",
      "/home/philip/Files/Keyword_spot/train/silence/yes_05b2db80_nohash_0.wav\n",
      "/home/philip/Files/Keyword_spot/train/silence/yes_190821dc_nohash_3.wav\n",
      "/home/philip/Files/Keyword_spot/train/silence/yes_36050ef3_nohash_1.wav\n",
      "/home/philip/Files/Keyword_spot/train/silence/yes_3f2b358d_nohash_1.wav\n",
      "/home/philip/Files/Keyword_spot/train/silence/yes_a6d586b7_nohash_1.wav\n",
      "/home/philip/Files/Keyword_spot/train/silence/yes_a6d586b7_nohash_3.wav\n",
      "/home/philip/Files/Keyword_spot/train/silence/yes_b959cd0c_nohash_1.wav\n",
      "/home/philip/Files/Keyword_spot/train/silence/yes_b959cd0c_nohash_3.wav\n",
      "/home/philip/Files/Keyword_spot/train/silence/yes_ced835d3_nohash_3.wav\n",
      "/home/philip/Files/Keyword_spot/train/silence/yes_ced835d3_nohash_4.wav\n",
      "/home/philip/Files/Keyword_spot/train/silence/yes_d197e3ae_nohash_0.wav\n",
      "/home/philip/Files/Keyword_spot/train/silence/yes_e96a5020_nohash_0.wav\n",
      "/home/philip/Files/Keyword_spot/train/silence/yes_e96a5020_nohash_1.wav\n",
      "/home/philip/Files/Keyword_spot/train/silence/yes_fd395b74_nohash_2.wav\n",
      "/home/philip/Files/Keyword_spot/train/silence/zero_179a61b7_nohash_1.wav\n",
      "/home/philip/Files/Keyword_spot/train/silence/zero_39999a0f_nohash_0.wav\n",
      "/home/philip/Files/Keyword_spot/train/silence/zero_3f2b358d_nohash_0.wav\n",
      "/home/philip/Files/Keyword_spot/train/silence/zero_742d6431_nohash_0.wav\n",
      "/home/philip/Files/Keyword_spot/train/silence/zero_742d6431_nohash_4.wav\n",
      "/home/philip/Files/Keyword_spot/train/silence/zero_7cf14c54_nohash_1.wav\n",
      "/home/philip/Files/Keyword_spot/train/silence/zero_8eb4a1bf_nohash_1.wav\n",
      "/home/philip/Files/Keyword_spot/train/silence/zero_d90b4138_nohash_2.wav\n"
     ]
    }
   ],
   "source": [
    "move_to_silence(s_list)\n",
    "delete_wrong_label(w_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "load_audio = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  },
  "widgets": {
   "state": {
    "52e72d0bdbb6466488002addbedc15a1": {
     "views": [
      {
       "cell_index": 19
      }
     ]
    }
   },
   "version": "1.2.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
