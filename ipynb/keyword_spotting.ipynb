{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import librosa\n",
    "import numpy as np\n",
    "import cv2\n",
    "from glob import glob\n",
    "import tqdm\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_root= '/home/philip/data/Keyword_spot/'\n",
    "join = os.path.join"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def audio_to_mel_to_db(audio_file):\n",
    "    y, sr = librosa.load(audio_file, sr=None)\n",
    "    mel = librosa.feature.melspectrogram(y,sr,hop_length=256)\n",
    "    db = librosa.power_to_db(mel, ref=np.min)\n",
    "    return db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "audio_folder = join(data_root,\"train/audio/\")\n",
    "valid_list = []\n",
    "with open(join(data_root,\"train/validation_list.txt\"),'r') as f:\n",
    "    for file in f:\n",
    "        full_filename = os.path.join(audio_folder,file)\n",
    "        valid_list.append(full_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "test_list = []\n",
    "with open(join(data_root,\"train/testing_list.txt\"),'r') as f:\n",
    "    for file in f:\n",
    "        full_filename = os.path.join(audio_folder,file)\n",
    "        test_list.append(full_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def del_n(string):\n",
    "    return string[:-1]\n",
    "valid_list = list(map(del_n,valid_list))\n",
    "test_list = list(map(del_n,test_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def handle_backgroud_audio(backgroud_audio_folder,target_image_folder,target_width):\n",
    "    counter = len(glob(target_image_folder))\n",
    "    for audio_file in glob(backgroud_audio_folder+\"***.wav\")+glob(backgroud_audio_folder+\"*.mp3\"):\n",
    "        audio_len = librosa.get_duration(filename=audio_file)\n",
    "        for off_set in np.arange(0,audio_len-0.5,0.5):\n",
    "            y, sr = librosa.load(audio_file, sr=None,offset=off_set,duration=1)\n",
    "            mel = librosa.feature.melspectrogram(y,sr,hop_length=256)\n",
    "            db = librosa.power_to_db(mel, ref=np.min)\n",
    "            counter += 1\n",
    "            image_path = os.path.join(target_image_folder,str(counter)+\".png\")\n",
    "            if db.shape[1]!=target_width:\n",
    "                db =cv2.resize(db,(target_width,128))\n",
    "            cv2.imwrite(image_path,db)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "handle_backgroud_audio(data_root+\"_background_noise_/\",data_root+\"train/silence\",63)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "handle_backgroud_audio(data_root+\"augment_background/\",data_root+\"train/silence\",63)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "db_length = []\n",
    "for i in tqdm.tqdm(glob(\"test/audio/*.wav\",recursive=True)):\n",
    "#     audio_path = i.replace(\"\\\\\",\"/\")\n",
    "    audio_path = i\n",
    "    db = audio_to_mel_to_db(audio_path)\n",
    "#     if not judge_invalid_data(db):\n",
    "#         continue\n",
    "    target_folder = \"test_image\"\n",
    "#     if audio_path in valid_list or audio_path in test_list:\n",
    "#         target_folder = \"valid_image\"\n",
    "    target_folder_path = os.path.join(\"test/\",target_folder)\n",
    "    if not os.path.isdir(target_folder_path):\n",
    "        os.mkdir(target_folder_path)\n",
    "    image_path = (audio_path.replace(\"audio\",target_folder)).replace(\"wav\",\"png\")\n",
    "    new_folder = os.path.dirname(image_path)\n",
    "    if not os.path.isdir(new_folder):\n",
    "        os.mkdir(new_folder)\n",
    "    if db.shape[1]!=63:\n",
    "        db =cv2.resize(db,(63,128))\n",
    "    cv2.imwrite(image_path,db)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for i in tqdm.tqdm(glob(data_root+\"train/audio/***/*.wav\",recursive=True)):\n",
    "#     audio_path = i.replace(\"\\\\\",\"/\")\n",
    "    audio_path = i\n",
    "    db = audio_to_mel_to_db(audio_path)\n",
    "#     if not judge_invalid_data(db):\n",
    "#         continue\n",
    "    target_folder = \"train_on_all/\"\n",
    "#     if audio_path in valid_list or audio_path in test_list:\n",
    "#         target_folder = \"valid_image\"\n",
    "    target_folder_path = os.path.join(data_root,target_folder)\n",
    "    if not os.path.isdir(target_folder_path):\n",
    "        os.mkdir(target_folder_path)\n",
    "    image_path = (audio_path.replace(\"audio\",target_folder)).replace(\"wav\",\"png\")\n",
    "    new_folder = os.path.dirname(image_path)\n",
    "    if not os.path.isdir(new_folder):\n",
    "        os.mkdir(new_folder)\n",
    "    if db.shape[1]!=63:\n",
    "        db =cv2.resize(db,(63,128))\n",
    "    cv2.imwrite(image_path,db)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "CNN_filter = 16\n",
    "CNN_layer = 3\n",
    "CNN_pooling = False\n",
    "CNN_output_shape = ()\n",
    "\n",
    "RNN_cell = 96\n",
    "RNN_layer = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import keras\n",
    "from model_builder import CRNNnetwork\n",
    "from keras.layers import InputLayer, Input\n",
    "from keras.preprocessing import image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "inputs= Input((128,63,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model = CRNNnetwork(inputs)\n",
    "model.compile(optimizer='adam',loss=keras.losses.categorical_crossentropy,metrics=[keras.metrics.categorical_accuracy])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "training_data_gen = image.ImageDataGenerator(width_shift_range=0.1)\n",
    "training_gen = training_data_gen.flow_from_directory(data_root+\"train/train_image\",class_mode=\"categorical\",target_size=(128,63),color_mode=\"grayscale\")\n",
    "valid_dataset_dir = os.path.join(data_root,\"train/valid_image\")\n",
    "valid_data_gen = keras.preprocessing.image.ImageDataGenerator().flow_from_directory(valid_dataset_dir,\n",
    "                                                                                    class_mode=\"categorical\",\n",
    "                                                                                    target_size=(128,63),\n",
    "                                                                                    color_mode=\"grayscale\",\n",
    "                                                                                    batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "model.fit_generator(training_gen,steps_per_epoch=100,epochs=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_audio = \"train/_background_noise_/doing_the_dishes.wav\"\n",
    "y, sr = librosa.load(test_audio, sr=None,offset=1,duration=1)\n",
    "mel = librosa.feature.melspectrogram(y,sr,hop_length=256)\n",
    "db = librosa.power_to_db(mel,ref=np.min)\n",
    "librosa.get_duration(filename=test_audio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.arange(0,9.1,0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def judge_invalid_data(db):\n",
    "    pixel_count = np.multiply(*db.shape)\n",
    "    activated = np.sum(db>(255/100))\n",
    "    return (activated/pixel_count)\n",
    "#     return activated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_file = \"/home/philip/data/Keyword_spot/train/audio/bird/4b25f620_nohash_0.wav\"\n",
    "db = audio_to_mel_to_db(test_file)\n",
    "a = judge_invalid_data(db)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import speech_recognition as sr\n",
    "# https://github.com/Uberi/speech_recognition\n",
    "\n",
    "from os import path\n",
    "AUDIO_FILE = \"train/audio/bird/1bc45db9_nohash_0.wav\"\n",
    "# AUDIO_FILE = path.join(path.dirname(path.realpath(__file__)), \"french.aiff\")\n",
    "# AUDIO_FILE = path.join(path.dirname(path.realpath(__file__)), \"chinese.flac\")\n",
    "\n",
    "# use the audio file as the audio source\n",
    "r = sr.Recognizer()\n",
    "with sr.AudioFile(AUDIO_FILE) as source:\n",
    "    audio = r.record(source)  # read the entire audio file\n",
    "\n",
    "# recognize speech using Sphinx\n",
    "try:\n",
    "    print(\"Sphinx thinks you said \" + r.recognize_sphinx(audio))\n",
    "except sr.UnknownValueError:\n",
    "    print(\"Sphinx could not understand audio\")\n",
    "except sr.RequestError as e:\n",
    "    print(\"Sphinx error; {0}\".format(e))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def detect_by_sphinx(AUDIO_FILE):\n",
    "    r = sr.Recognizer()\n",
    "    label = AUDIO_FILE.split(\"/\")[-2]\n",
    "    with sr.AudioFile(AUDIO_FILE) as source:\n",
    "        audio = r.record(source)\n",
    "    try:\n",
    "        \n",
    "        if r.recognize_sphinx(audio)== label:\n",
    "            return (\"good\",AUDIO_FILE)\n",
    "        else:\n",
    "            return (\"bad\",AUDIO_FILE)\n",
    "    except sr.UnknownValueError:\n",
    "        print(\"Speech Recognition could not understand audio\")\n",
    "        return (\"bad\",AUDIO_FILE)\n",
    "    except sr.RequestError as e:\n",
    "        print(\"Sphinx error; {0}\".format(e))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_by_google(AUDIO_FILE):\n",
    "    r = sr.Recognizer()\n",
    "    with sr.AudioFile(AUDIO_FILE) as source:\n",
    "        audio = r.record(source)\n",
    "    try:\n",
    "        r.recognize_google(audio)\n",
    "#         ok_file.write(AUDIO_FILE+\"\\n\")\n",
    "        return (\"good\",AUDIO_FILE)\n",
    "    except sr.UnknownValueError:\n",
    "#         print(\"Google Speech Recognition could not understand audio\")\n",
    "#         bad_file.write(AUDIO_FILE+\"\\n\")\n",
    "        return ('bad',AUDIO_FILE)\n",
    "    except sr.RequestError as e:\n",
    "        print(\"Could not request results from Google Speech Recognition service; {0}\".format(e))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "good = []\n",
    "bad = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from multiprocessing import Pool\n",
    "from glob import glob\n",
    "# ok_file = open(\"ok.txt\",\"w\")\n",
    "# bad_file = open(\"bad.txt\",\"w\")\n",
    "\n",
    "p = Pool(4)\n",
    "files = glob(\"./train/audio/***/*.wav\",recursive=True)\n",
    "re = p.map(detect_by_sphinx,files)\n",
    "# bad_file.close()\n",
    "# ok_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "good = [_[1] for _ in list(filter(lambda x:x[0]=='good',re))]\n",
    "bad = [_[1] for _ in list(filter(lambda x:x[0]=='bad',re))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(good)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(bad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import tqdm\n",
    "\n",
    "ok_file = open(\"ok.txt\",\"w\")\n",
    "bad_file = open(\"bad.txt\",\"w\")\n",
    "for i in bad:\n",
    "    bad_file.write(i+\"\\n\")\n",
    "for i in good:\n",
    "    ok_file.write(i+\"\\n\")\n",
    "bad_file.close()\n",
    "ok_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "GOOGLE_CLOUD_SPEECH_CREDENTIALS = r\"\"\"INSERT THE CONTENTS OF THE GOOGLE CLOUD SPEECH JSON CREDENTIALS FILE HERE\"\"\"\n",
    "try:\n",
    "    print(\"Google Cloud Speech thinks you said \" + r.recognize_google(audio))#, credentials_json=GOOGLE_CLOUD_SPEECH_CREDENTIALS))\n",
    "except sr.UnknownValueError:\n",
    "    print(\"Google Cloud Speech could not understand audio\")\n",
    "except sr.RequestError as e:\n",
    "    print(\"Could not request results from Google Cloud Speech service; {0}\".format(e))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "import os\n",
    "with open(\"bad.txt\") as bad:\n",
    "    for i in list(map(del_n,bad)):\n",
    "        dir_folder = os.path.dirname(i).replace(\"audio\",\"hard_example\")\n",
    "        if not os.path.isdir(dir_folder):\n",
    "            os.mkdir(dir_folder)\n",
    "        shutil.copy(i,dir_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
